/home/mt1/21CS60D06/MTP/wkg_code/fair_dummies
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python38.zip
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/lib-dynload
/home/mt1/21CS60D06/.local/lib/python3.8/site-packages
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages
/home/mt1/21CS60D06/MTP/wkg_code/fair_dummies/others
/home/mt1/21CS60D06/MTP/wkg_code/fair_dummies/others/third_party/fairness_aware_learning
/home/mt1/21CS60D06/MTP/wkg_code/fair_dummies/others/third_party/cqr
nursery
Baseline
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.664596
Group 0 : Average length: 1.044255
Group 1 : Percentage in the range (expecting 90.00): 89.033742
Group 1 : Average length: 1.012270
Init Loss = 0.7286677
Final Loss = 0.31448066
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 1
Coverage 0 = 0.8866459627329193
Coverage 1 = 0.8903374233128835
Length 0 = 1.0442546583850931
Length 1 = 1.0122699386503067
Prediction Error = 0.12037037037037035
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 01 | Avg. Pred Err = 0.1204 | Avg Length 0 = 1.0443 | Avg Length 1 = 1.0123 | Avg Coverage 0 = 0.8866 | Avg Coverage 1 = 0.8903 | Avg p_val = 0.0010 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.810427
Group 0 : Average length: 1.080569
Group 1 : Percentage in the range (expecting 90.00): 88.838612
Group 1 : Average length: 1.000000
Init Loss = 0.6210214
Final Loss = 0.34178433
Fair dummies test (classification score), p-value: 0.015984015984015984
experiment = 2
Coverage 0 = 0.8981042654028436
Coverage 1 = 0.8883861236802413
Length 0 = 1.080568720379147
Length 1 = 1.0
Prediction Error = 0.12654320987654322
p_val = 0.015984015984015984
Baseline_linear_model
Num experiments 02 | Avg. Pred Err = 0.1235 | Avg Length 0 = 1.0624 | Avg Length 1 = 1.0061 | Avg Coverage 0 = 0.8924 | Avg Coverage 1 = 0.8894 | Avg p_val = 0.0085 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.399386
Group 0 : Average length: 1.093702
Group 1 : Percentage in the range (expecting 90.00): 90.542636
Group 1 : Average length: 1.031008
Init Loss = 0.67555124
Final Loss = 0.35453537
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 3
Coverage 0 = 0.9039938556067588
Coverage 1 = 0.9054263565891473
Length 0 = 1.0937019969278035
Length 1 = 1.0310077519379846
Prediction Error = 0.12345679012345678
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 03 | Avg. Pred Err = 0.1235 | Avg Length 0 = 1.0728 | Avg Length 1 = 1.0144 | Avg Coverage 0 = 0.8962 | Avg Coverage 1 = 0.8947 | Avg p_val = 0.0060 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.435459
Group 0 : Average length: 1.115086
Group 1 : Percentage in the range (expecting 90.00): 90.199081
Group 1 : Average length: 1.032925
Init Loss = 0.68938917
Final Loss = 0.35819957
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 4
Coverage 0 = 0.9043545878693624
Coverage 1 = 0.9019908116385911
Length 0 = 1.115085536547434
Length 1 = 1.0329249617151608
Prediction Error = 0.1304012345679012
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 04 | Avg. Pred Err = 0.1252 | Avg Length 0 = 1.0834 | Avg Length 1 = 1.0191 | Avg Coverage 0 = 0.8983 | Avg Coverage 1 = 0.8965 | Avg p_val = 0.0047 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.007686
Group 0 : Average length: 1.068409
Group 1 : Percentage in the range (expecting 90.00): 88.690937
Group 1 : Average length: 1.027111
Init Loss = 0.7410438
Final Loss = 0.35499987
Fair dummies test (classification score), p-value: 0.13986013986013987
experiment = 5
Coverage 0 = 0.9000768639508071
Coverage 1 = 0.8869093725793958
Length 0 = 1.0684089162182937
Length 1 = 1.027110766847405
Prediction Error = 0.13117283950617287
p_val = 0.13986013986013987
Baseline_linear_model
Num experiments 05 | Avg. Pred Err = 0.1264 | Avg Length 0 = 1.0804 | Avg Length 1 = 1.0207 | Avg Coverage 0 = 0.8986 | Avg Coverage 1 = 0.8946 | Avg p_val = 0.0318 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.676358
Group 0 : Average length: 1.074216
Group 1 : Percentage in the range (expecting 90.00): 91.439689
Group 1 : Average length: 1.020233
Init Loss = 0.75982434
Final Loss = 0.32872
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 6
Coverage 0 = 0.8867635807192042
Coverage 1 = 0.914396887159533
Length 0 = 1.0742157612853864
Length 1 = 1.0202334630350194
Prediction Error = 0.12268518518518523
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 06 | Avg. Pred Err = 0.1258 | Avg Length 0 = 1.0794 | Avg Length 1 = 1.0206 | Avg Coverage 0 = 0.8967 | Avg Coverage 1 = 0.8979 | Avg p_val = 0.0266 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.970655
Group 0 : Average length: 1.151242
Group 1 : Percentage in the range (expecting 90.00): 90.894695
Group 1 : Average length: 1.107680
Init Loss = 0.7055583
Final Loss = 0.37263718
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 7
Coverage 0 = 0.909706546275395
Coverage 1 = 0.9089469517022961
Length 0 = 1.1512415349887133
Length 1 = 1.107680126682502
Prediction Error = 0.1415895061728395
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 07 | Avg. Pred Err = 0.1280 | Avg Length 0 = 1.0896 | Avg Length 1 = 1.0330 | Avg Coverage 0 = 0.8985 | Avg Coverage 1 = 0.8995 | Avg p_val = 0.0230 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.491037
Group 0 : Average length: 1.088854
Group 1 : Percentage in the range (expecting 90.00): 89.533995
Group 1 : Average length: 1.035905
Init Loss = 0.6456581
Final Loss = 0.37121436
Fair dummies test (classification score), p-value: 0.03496503496503497
experiment = 8
Coverage 0 = 0.9049103663289166
Coverage 1 = 0.8953399541634836
Length 0 = 1.0888542478565861
Length 1 = 1.0359052711993888
Prediction Error = 0.128858024691358
p_val = 0.03496503496503497
Baseline_linear_model
Num experiments 08 | Avg. Pred Err = 0.1281 | Avg Length 0 = 1.0895 | Avg Length 1 = 1.0334 | Avg Coverage 0 = 0.8993 | Avg Coverage 1 = 0.8990 | Avg p_val = 0.0245 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.929285
Group 0 : Average length: 1.105304
Group 1 : Percentage in the range (expecting 90.00): 90.007746
Group 1 : Average length: 1.013943
Init Loss = 0.67881733
Final Loss = 0.35947862
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 9
Coverage 0 = 0.9192928516525749
Coverage 1 = 0.9000774593338497
Length 0 = 1.1053036126056879
Length 1 = 1.0139426800929512
Prediction Error = 0.11651234567901236
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 09 | Avg. Pred Err = 0.1268 | Avg Length 0 = 1.0913 | Avg Length 1 = 1.0312 | Avg Coverage 0 = 0.9015 | Avg Coverage 1 = 0.8991 | Avg p_val = 0.0219 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.024390
Group 0 : Average length: 1.054116
Group 1 : Percentage in the range (expecting 90.00): 89.765625
Group 1 : Average length: 1.042969
Init Loss = 0.81051
Final Loss = 0.3682059
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 10
Coverage 0 = 0.8902439024390244
Coverage 1 = 0.89765625
Length 0 = 1.0541158536585367
Length 1 = 1.04296875
Prediction Error = 0.12654320987654322
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 10 | Avg. Pred Err = 0.1268 | Avg Length 0 = 1.0876 | Avg Length 1 = 1.0324 | Avg Coverage 0 = 0.9004 | Avg Coverage 1 = 0.8989 | Avg p_val = 0.0198 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.200617
Group 0 : Average length: 1.128858
Group 1 : Percentage in the range (expecting 90.00): 91.049383
Group 1 : Average length: 1.024691
Init Loss = 0.6854965
Final Loss = 0.34857714
Fair dummies test (classification score), p-value: 0.003996003996003996
experiment = 11
Coverage 0 = 0.9020061728395061
Coverage 1 = 0.9104938271604939
Length 0 = 1.128858024691358
Length 1 = 1.0246913580246915
Prediction Error = 0.12538580246913578
p_val = 0.003996003996003996
Baseline_linear_model
Num experiments 11 | Avg. Pred Err = 0.1267 | Avg Length 0 = 1.0913 | Avg Length 1 = 1.0317 | Avg Coverage 0 = 0.9006 | Avg Coverage 1 = 0.9000 | Avg p_val = 0.0183 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.685142
Group 0 : Average length: 1.077752
Group 1 : Percentage in the range (expecting 90.00): 89.791183
Group 1 : Average length: 1.034029
Init Loss = 0.72458434
Final Loss = 0.36163336
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 12
Coverage 0 = 0.9068514241724404
Coverage 1 = 0.8979118329466357
Length 0 = 1.077752117013087
Length 1 = 1.034029389017788
Prediction Error = 0.12191358024691357
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 12 | Avg. Pred Err = 0.1263 | Avg Length 0 = 1.0902 | Avg Length 1 = 1.0319 | Avg Coverage 0 = 0.9011 | Avg Coverage 1 = 0.8998 | Avg p_val = 0.0169 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.918458
Group 0 : Average length: 1.085248
Group 1 : Percentage in the range (expecting 90.00): 90.024135
Group 1 : Average length: 1.051488
Init Loss = 0.74927795
Final Loss = 0.35127297
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 13
Coverage 0 = 0.899184581171238
Coverage 1 = 0.9002413515687852
Length 0 = 1.0852483320978503
Length 1 = 1.0514883346741755
Prediction Error = 0.12962962962962965
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 13 | Avg. Pred Err = 0.1265 | Avg Length 0 = 1.0898 | Avg Length 1 = 1.0334 | Avg Coverage 0 = 0.9009 | Avg Coverage 1 = 0.8999 | Avg p_val = 0.0157 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.108108
Group 0 : Average length: 1.034749
Group 1 : Percentage in the range (expecting 90.00): 90.285274
Group 1 : Average length: 1.043177
Init Loss = 0.6593611
Final Loss = 0.33914962
Fair dummies test (classification score), p-value: 0.008991008991008992
experiment = 14
Coverage 0 = 0.8810810810810811
Coverage 1 = 0.9028527370855821
Length 0 = 1.0347490347490347
Length 1 = 1.0431765612952968
Prediction Error = 0.126929012345679
p_val = 0.008991008991008992
Baseline_linear_model
Num experiments 14 | Avg. Pred Err = 0.1266 | Avg Length 0 = 1.0859 | Avg Length 1 = 1.0341 | Avg Coverage 0 = 0.8995 | Avg Coverage 1 = 0.9001 | Avg p_val = 0.0152 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.199689
Group 0 : Average length: 1.064491
Group 1 : Percentage in the range (expecting 90.00): 90.268199
Group 1 : Average length: 1.032950
Init Loss = 0.7352383
Final Loss = 0.34966633
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 15
Coverage 0 = 0.891996891996892
Coverage 1 = 0.9026819923371647
Length 0 = 1.0644910644910646
Length 1 = 1.0329501915708812
Prediction Error = 0.12731481481481477
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 15 | Avg. Pred Err = 0.1266 | Avg Length 0 = 1.0845 | Avg Length 1 = 1.0340 | Avg Coverage 0 = 0.8990 | Avg Coverage 1 = 0.9002 | Avg p_val = 0.0143 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.750988
Group 0 : Average length: 1.053755
Group 1 : Percentage in the range (expecting 90.00): 90.128109
Group 1 : Average length: 1.039940
Init Loss = 0.791499
Final Loss = 0.3692392
Fair dummies test (classification score), p-value: 0.001998001998001998
experiment = 16
Coverage 0 = 0.9075098814229249
Coverage 1 = 0.9012810851544838
Length 0 = 1.0537549407114624
Length 1 = 1.039939713639789
Prediction Error = 0.11805555555555558
p_val = 0.001998001998001998
Baseline_linear_model
Num experiments 16 | Avg. Pred Err = 0.1261 | Avg Length 0 = 1.0825 | Avg Length 1 = 1.0344 | Avg Coverage 0 = 0.8995 | Avg Coverage 1 = 0.9003 | Avg p_val = 0.0135 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.544965
Group 0 : Average length: 1.069946
Group 1 : Percentage in the range (expecting 90.00): 88.071263
Group 1 : Average length: 1.054996
Init Loss = 0.73773247
Final Loss = 0.34656677
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 17
Coverage 0 = 0.9154496541122213
Coverage 1 = 0.8807126258714175
Length 0 = 1.0699461952344351
Length 1 = 1.0549961270333075
Prediction Error = 0.12770061728395066
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 17 | Avg. Pred Err = 0.1262 | Avg Length 0 = 1.0818 | Avg Length 1 = 1.0356 | Avg Coverage 0 = 0.9005 | Avg Coverage 1 = 0.8992 | Avg p_val = 0.0128 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.731801
Group 0 : Average length: 1.101916
Group 1 : Percentage in the range (expecting 90.00): 90.598291
Group 1 : Average length: 1.073815
Init Loss = 0.5735418
Final Loss = 0.3672247
Fair dummies test (classification score), p-value: 0.04295704295704296
experiment = 18
Coverage 0 = 0.8973180076628352
Coverage 1 = 0.905982905982906
Length 0 = 1.1019157088122606
Length 1 = 1.0738150738150738
Prediction Error = 0.1361882716049383
p_val = 0.04295704295704296
Baseline_linear_model
Num experiments 18 | Avg. Pred Err = 0.1267 | Avg Length 0 = 1.0829 | Avg Length 1 = 1.0377 | Avg Coverage 0 = 0.9003 | Avg Coverage 1 = 0.8995 | Avg p_val = 0.0144 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.687500
Group 0 : Average length: 1.067969
Group 1 : Percentage in the range (expecting 90.00): 91.158537
Group 1 : Average length: 1.048780
Init Loss = 0.8140528
Final Loss = 0.34574857
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 19
Coverage 0 = 0.896875
Coverage 1 = 0.9115853658536586
Length 0 = 1.06796875
Length 1 = 1.048780487804878
Prediction Error = 0.12422839506172845
p_val = 0.000999000999000999
Baseline_linear_model
Num experiments 19 | Avg. Pred Err = 0.1266 | Avg Length 0 = 1.0821 | Avg Length 1 = 1.0383 | Avg Coverage 0 = 0.9001 | Avg Coverage 1 = 0.9002 | Avg p_val = 0.0137 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 92.384615
Group 0 : Average length: 1.143077
Group 1 : Percentage in the range (expecting 90.00): 89.628483
Group 1 : Average length: 1.079721
Init Loss = 0.7149639
Final Loss = 0.37221757
Fair dummies test (classification score), p-value: 0.00999000999000999
experiment = 20
Coverage 0 = 0.9238461538461539
Coverage 1 = 0.8962848297213623
Length 0 = 1.143076923076923
Length 1 = 1.0797213622291022
Prediction Error = 0.1377314814814815
p_val = 0.00999000999000999
Baseline_linear_model
Num experiments 20 | Avg. Pred Err = 0.1272 | Avg Length 0 = 1.0852 | Avg Length 1 = 1.0404 | Avg Coverage 0 = 0.9013 | Avg Coverage 1 = 0.9000 | Avg p_val = 0.0135 | min p_val = 0.0010
======== Done =========
nursery
Baseline
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.984472
Group 0 : Average length: 0.958075
Group 1 : Percentage in the range (expecting 90.00): 86.963190
Group 1 : Average length: 0.928681
Init Loss = 0.7333825
Final Loss = 0.27308074
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 1
Coverage 0 = 0.8998447204968945
Coverage 1 = 0.8696319018404908
Length 0 = 0.9580745341614907
Length 1 = 0.928680981595092
Prediction Error = 0.08140432098765427
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 01 | Avg. Pred Err = 0.0814 | Avg Length 0 = 0.9581 | Avg Length 1 = 0.9287 | Avg Coverage 0 = 0.8998 | Avg Coverage 1 = 0.8696 | Avg p_val = 0.0010 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 92.180095
Group 0 : Average length: 0.994471
Group 1 : Percentage in the range (expecting 90.00): 88.838612
Group 1 : Average length: 0.931373
Init Loss = 0.73749804
Final Loss = 0.2740799
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 2
Coverage 0 = 0.9218009478672986
Coverage 1 = 0.8883861236802413
Length 0 = 0.9944707740916272
Length 1 = 0.9313725490196079
Prediction Error = 0.07060185185185186
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 02 | Avg. Pred Err = 0.0760 | Avg Length 0 = 0.9763 | Avg Length 1 = 0.9300 | Avg Coverage 0 = 0.9108 | Avg Coverage 1 = 0.8790 | Avg p_val = 0.0010 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.013825
Group 0 : Average length: 0.964670
Group 1 : Percentage in the range (expecting 90.00): 88.294574
Group 1 : Average length: 0.929457
Init Loss = 0.69903857
Final Loss = 0.2964208
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 3
Coverage 0 = 0.9101382488479263
Coverage 1 = 0.8829457364341086
Length 0 = 0.9646697388632872
Length 1 = 0.9294573643410853
Prediction Error = 0.07214506172839508
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 03 | Avg. Pred Err = 0.0747 | Avg Length 0 = 0.9724 | Avg Length 1 = 0.9298 | Avg Coverage 0 = 0.9106 | Avg Coverage 1 = 0.8803 | Avg p_val = 0.0010 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.290824
Group 0 : Average length: 1.011664
Group 1 : Percentage in the range (expecting 90.00): 91.117917
Group 1 : Average length: 0.954058
Init Loss = 0.6548804
Final Loss = 0.28824818
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 4
Coverage 0 = 0.9129082426127527
Coverage 1 = 0.9111791730474732
Length 0 = 1.0116640746500778
Length 1 = 0.9540581929555896
Prediction Error = 0.0864197530864198
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 04 | Avg. Pred Err = 0.0776 | Avg Length 0 = 0.9822 | Avg Length 1 = 0.9359 | Avg Coverage 0 = 0.9112 | Avg Coverage 1 = 0.8880 | Avg p_val = 0.0010 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.853190
Group 0 : Average length: 0.968486
Group 1 : Percentage in the range (expecting 90.00): 89.930287
Group 1 : Average length: 0.946553
Init Loss = 0.69945705
Final Loss = 0.2743285
Fair dummies test (classification score), p-value: 0.001998001998001998
experiment = 5
Coverage 0 = 0.9085318985395849
Coverage 1 = 0.8993028659953525
Length 0 = 0.9684857801691007
Length 1 = 0.9465530596436871
Prediction Error = 0.06867283950617287
p_val = 0.001998001998001998
Baseline_deep_model
Num experiments 05 | Avg. Pred Err = 0.0758 | Avg Length 0 = 0.9795 | Avg Length 1 = 0.9380 | Avg Coverage 0 = 0.9106 | Avg Coverage 1 = 0.8903 | Avg p_val = 0.0012 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.283091
Group 0 : Average length: 0.957154
Group 1 : Percentage in the range (expecting 90.00): 88.482490
Group 1 : Average length: 0.927626
Init Loss = 0.5510283
Final Loss = 0.2746309
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 6
Coverage 0 = 0.9028309104820199
Coverage 1 = 0.8848249027237354
Length 0 = 0.9571537872991583
Length 1 = 0.9276264591439689
Prediction Error = 0.07407407407407407
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 06 | Avg. Pred Err = 0.0756 | Avg Length 0 = 0.9758 | Avg Length 1 = 0.9363 | Avg Coverage 0 = 0.9093 | Avg Coverage 1 = 0.8894 | Avg p_val = 0.0012 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.337096
Group 0 : Average length: 0.959368
Group 1 : Percentage in the range (expecting 90.00): 90.419636
Group 1 : Average length: 0.950911
Init Loss = 0.7347199
Final Loss = 0.278659
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 7
Coverage 0 = 0.8833709556057185
Coverage 1 = 0.9041963578780681
Length 0 = 0.9593679458239278
Length 1 = 0.950910530482977
Prediction Error = 0.08680555555555558
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 07 | Avg. Pred Err = 0.0772 | Avg Length 0 = 0.9734 | Avg Length 1 = 0.9384 | Avg Coverage 0 = 0.9056 | Avg Coverage 1 = 0.8915 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.789556
Group 0 : Average length: 0.960249
Group 1 : Percentage in the range (expecting 90.00): 90.909091
Group 1 : Average length: 0.951872
Init Loss = 0.63483
Final Loss = 0.2725684
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 8
Coverage 0 = 0.8978955572876072
Coverage 1 = 0.9090909090909091
Length 0 = 0.9602494154325799
Length 1 = 0.9518716577540107
Prediction Error = 0.07253086419753085
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 08 | Avg. Pred Err = 0.0766 | Avg Length 0 = 0.9718 | Avg Length 1 = 0.9401 | Avg Coverage 0 = 0.9047 | Avg Coverage 1 = 0.8937 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 92.621061
Group 0 : Average length: 0.990776
Group 1 : Percentage in the range (expecting 90.00): 90.162665
Group 1 : Average length: 0.934934
Init Loss = 0.5914805
Final Loss = 0.29369867
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 9
Coverage 0 = 0.9262106072252114
Coverage 1 = 0.9016266460108443
Length 0 = 0.9907763259031515
Length 1 = 0.9349341595662277
Prediction Error = 0.06288580246913578
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 09 | Avg. Pred Err = 0.0751 | Avg Length 0 = 0.9739 | Avg Length 1 = 0.9395 | Avg Coverage 0 = 0.9071 | Avg Coverage 1 = 0.8946 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.472561
Group 0 : Average length: 0.989329
Group 1 : Percentage in the range (expecting 90.00): 88.906250
Group 1 : Average length: 0.928125
Init Loss = 0.73548764
Final Loss = 0.2745575
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 10
Coverage 0 = 0.9047256097560976
Coverage 1 = 0.8890625
Length 0 = 0.989329268292683
Length 1 = 0.928125
Prediction Error = 0.0825617283950617
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 10 | Avg. Pred Err = 0.0758 | Avg Length 0 = 0.9754 | Avg Length 1 = 0.9384 | Avg Coverage 0 = 0.9068 | Avg Coverage 1 = 0.8940 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.432099
Group 0 : Average length: 0.982253
Group 1 : Percentage in the range (expecting 90.00): 89.274691
Group 1 : Average length: 0.910494
Init Loss = 0.72885346
Final Loss = 0.2734698
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 11
Coverage 0 = 0.904320987654321
Coverage 1 = 0.8927469135802469
Length 0 = 0.9822530864197531
Length 1 = 0.9104938271604939
Prediction Error = 0.06674382716049387
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 11 | Avg. Pred Err = 0.0750 | Avg Length 0 = 0.9760 | Avg Length 1 = 0.9358 | Avg Coverage 0 = 0.9066 | Avg Coverage 1 = 0.8939 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.070054
Group 0 : Average length: 0.987683
Group 1 : Percentage in the range (expecting 90.00): 89.327146
Group 1 : Average length: 0.931168
Init Loss = 0.661774
Final Loss = 0.2816896
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 12
Coverage 0 = 0.9107005388760585
Coverage 1 = 0.8932714617169374
Length 0 = 0.9876828329484219
Length 1 = 0.9311678267594741
Prediction Error = 0.08140432098765427
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 12 | Avg. Pred Err = 0.0755 | Avg Length 0 = 0.9770 | Avg Length 1 = 0.9354 | Avg Coverage 0 = 0.9069 | Avg Coverage 1 = 0.8939 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.621942
Group 0 : Average length: 0.958488
Group 1 : Percentage in the range (expecting 90.00): 90.506838
Group 1 : Average length: 0.960579
Init Loss = 0.55019265
Final Loss = 0.28468138
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 13
Coverage 0 = 0.8962194217939214
Coverage 1 = 0.9050683829444891
Length 0 = 0.9584877687175686
Length 1 = 0.9605792437650845
Prediction Error = 0.08333333333333337
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 13 | Avg. Pred Err = 0.0761 | Avg Length 0 = 0.9756 | Avg Length 1 = 0.9374 | Avg Coverage 0 = 0.9061 | Avg Coverage 1 = 0.8947 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.266409
Group 0 : Average length: 0.964479
Group 1 : Percentage in the range (expecting 90.00): 91.287587
Group 1 : Average length: 0.963763
Init Loss = 0.6291462
Final Loss = 0.2966469
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 14
Coverage 0 = 0.8926640926640926
Coverage 1 = 0.912875867386276
Length 0 = 0.9644787644787645
Length 1 = 0.9637625289128758
Prediction Error = 0.07754629629629628
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 14 | Avg. Pred Err = 0.0762 | Avg Length 0 = 0.9748 | Avg Length 1 = 0.9393 | Avg Coverage 0 = 0.9052 | Avg Coverage 1 = 0.8960 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.655789
Group 0 : Average length: 0.964258
Group 1 : Percentage in the range (expecting 90.00): 91.034483
Group 1 : Average length: 0.956322
Init Loss = 0.6456595
Final Loss = 0.28379428
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 15
Coverage 0 = 0.8865578865578866
Coverage 1 = 0.9103448275862069
Length 0 = 0.9642579642579643
Length 1 = 0.9563218390804598
Prediction Error = 0.07600308641975306
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 15 | Avg. Pred Err = 0.0762 | Avg Length 0 = 0.9741 | Avg Length 1 = 0.9404 | Avg Coverage 0 = 0.9039 | Avg Coverage 1 = 0.8970 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.909091
Group 0 : Average length: 0.985771
Group 1 : Percentage in the range (expecting 90.00): 90.354182
Group 1 : Average length: 0.954785
Init Loss = 0.7583837
Final Loss = 0.28378046
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 16
Coverage 0 = 0.9090909090909091
Coverage 1 = 0.9035418236623964
Length 0 = 0.9857707509881423
Length 1 = 0.9547852298417483
Prediction Error = 0.08526234567901236
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 16 | Avg. Pred Err = 0.0768 | Avg Length 0 = 0.9748 | Avg Length 1 = 0.9413 | Avg Coverage 0 = 0.9042 | Avg Coverage 1 = 0.8974 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.392006
Group 0 : Average length: 0.958493
Group 1 : Percentage in the range (expecting 90.00): 89.542990
Group 1 : Average length: 0.942680
Init Loss = 0.72628015
Final Loss = 0.29263324
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 17
Coverage 0 = 0.9039200614911607
Coverage 1 = 0.895429899302866
Length 0 = 0.9584934665641814
Length 1 = 0.9426800929512006
Prediction Error = 0.08179012345679015
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 17 | Avg. Pred Err = 0.0771 | Avg Length 0 = 0.9739 | Avg Length 1 = 0.9414 | Avg Coverage 0 = 0.9042 | Avg Coverage 1 = 0.8973 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.655172
Group 0 : Average length: 0.965517
Group 1 : Percentage in the range (expecting 90.00): 88.500389
Group 1 : Average length: 0.926962
Init Loss = 0.6610311
Final Loss = 0.28256154
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 18
Coverage 0 = 0.896551724137931
Coverage 1 = 0.885003885003885
Length 0 = 0.9655172413793104
Length 1 = 0.9269619269619269
Prediction Error = 0.07638888888888884
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 18 | Avg. Pred Err = 0.0770 | Avg Length 0 = 0.9734 | Avg Length 1 = 0.9406 | Avg Coverage 0 = 0.9038 | Avg Coverage 1 = 0.8966 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.750000
Group 0 : Average length: 0.952344
Group 1 : Percentage in the range (expecting 90.00): 89.939024
Group 1 : Average length: 0.928354
Init Loss = 0.75146174
Final Loss = 0.27988404
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 19
Coverage 0 = 0.8875
Coverage 1 = 0.899390243902439
Length 0 = 0.95234375
Length 1 = 0.9283536585365854
Prediction Error = 0.06944444444444442
p_val = 0.000999000999000999
Baseline_deep_model
Num experiments 19 | Avg. Pred Err = 0.0766 | Avg Length 0 = 0.9723 | Avg Length 1 = 0.9399 | Avg Coverage 0 = 0.9029 | Avg Coverage 1 = 0.8967 | Avg p_val = 0.0011 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.769231
Group 0 : Average length: 0.964615
Group 1 : Percentage in the range (expecting 90.00): 89.241486
Group 1 : Average length: 0.921827
Init Loss = 0.72918487
Final Loss = 0.2725325
Fair dummies test (classification score), p-value: 0.005994005994005994
experiment = 20
Coverage 0 = 0.8976923076923077
Coverage 1 = 0.8924148606811145
Length 0 = 0.9646153846153847
Length 1 = 0.9218266253869969
Prediction Error = 0.07214506172839508
p_val = 0.005994005994005994
Baseline_deep_model
Num experiments 20 | Avg. Pred Err = 0.0764 | Avg Length 0 = 0.9719 | Avg Length 1 = 0.9390 | Avg Coverage 0 = 0.9027 | Avg Coverage 1 = 0.8965 | Avg p_val = 0.0013 | min p_val = 0.0010
======== Done =========
nursery
HGR
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.5051233 ACC = 0.232055569848212
mu = 0.98 Loss = 0.66620964 ACC = 0.6439413429379984
Group 0 : Percentage in the range (expecting 90.00): 88.509317
Group 0 : Average length: 1.347826
Group 1 : Percentage in the range (expecting 90.00): 89.570552
Group 1 : Average length: 1.282975
Init Loss = 0.69826543
Final Loss = 0.58927554
Fair dummies test (classification score), p-value: 0.7252747252747253
experiment = 1
Coverage 0 = 0.8850931677018633
Coverage 1 = 0.8957055214723927
Length 0 = 1.3478260869565217
Length 1 = 1.2829754601226995
Prediction Error = 0.3545524691358025
p_val = 0.7252747252747253
HGR_linear_model
Num experiments 01 | Avg. Pred Err = 0.3546 | Avg Length 0 = 1.3478 | Avg Length 1 = 1.2830 | Avg Coverage 0 = 0.8851 | Avg Coverage 1 = 0.8957 | Avg p_val = 0.7253 | min p_val = 0.7253
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3318685 ACC = 0.3699511191149987
mu = 0.98 Loss = 0.6597276 ACC = 0.6664522768201698
Group 0 : Percentage in the range (expecting 90.00): 88.941548
Group 0 : Average length: 1.270142
Group 1 : Percentage in the range (expecting 90.00): 88.461538
Group 1 : Average length: 1.270739
Init Loss = 0.69050944
Final Loss = 0.5829697
Fair dummies test (classification score), p-value: 0.058941058941058944
experiment = 2
Coverage 0 = 0.8894154818325435
Coverage 1 = 0.8846153846153846
Length 0 = 1.2701421800947867
Length 1 = 1.2707390648567118
Prediction Error = 0.345679012345679
p_val = 0.058941058941058944
HGR_linear_model
Num experiments 02 | Avg. Pred Err = 0.3501 | Avg Length 0 = 1.3090 | Avg Length 1 = 1.2769 | Avg Coverage 0 = 0.8873 | Avg Coverage 1 = 0.8902 | Avg p_val = 0.3921 | min p_val = 0.0589
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4996363 ACC = 0.19745304862361718
mu = 0.98 Loss = 0.6375162 ACC = 0.6480576279907384
Group 0 : Percentage in the range (expecting 90.00): 91.781874
Group 0 : Average length: 1.417051
Group 1 : Percentage in the range (expecting 90.00): 90.232558
Group 1 : Average length: 1.316279
Init Loss = 0.71938246
Final Loss = 0.56997114
Fair dummies test (classification score), p-value: 0.33666333666333664
experiment = 3
Coverage 0 = 0.9178187403993856
Coverage 1 = 0.9023255813953488
Length 0 = 1.4170506912442395
Length 1 = 1.3162790697674418
Prediction Error = 0.3599537037037037
p_val = 0.33666333666333664
HGR_linear_model
Num experiments 03 | Avg. Pred Err = 0.3534 | Avg Length 0 = 1.3450 | Avg Length 1 = 1.2900 | Avg Coverage 0 = 0.8974 | Avg Coverage 1 = 0.8942 | Avg p_val = 0.3736 | min p_val = 0.0589
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3119063 ACC = 0.3810136351942372
mu = 0.98 Loss = 0.6477937 ACC = 0.6489580653460252
Group 0 : Percentage in the range (expecting 90.00): 88.491446
Group 0 : Average length: 1.319596
Group 1 : Percentage in the range (expecting 90.00): 91.117917
Group 1 : Average length: 1.292496
Init Loss = 0.707146
Final Loss = 0.5815175
Fair dummies test (classification score), p-value: 0.2097902097902098
experiment = 4
Coverage 0 = 0.8849144634525661
Coverage 1 = 0.9111791730474732
Length 0 = 1.3195956454121307
Length 1 = 1.2924961715160797
Prediction Error = 0.34992283950617287
p_val = 0.2097902097902098
HGR_linear_model
Num experiments 04 | Avg. Pred Err = 0.3525 | Avg Length 0 = 1.3387 | Avg Length 1 = 1.2906 | Avg Coverage 0 = 0.8943 | Avg Coverage 1 = 0.8985 | Avg p_val = 0.3327 | min p_val = 0.0589
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.5630368 ACC = 0.20118343195266272
mu = 0.98 Loss = 1.1087304 ACC = 0.3325186519166452
Group 0 : Percentage in the range (expecting 90.00): 90.238278
Group 0 : Average length: 2.272867
Group 1 : Percentage in the range (expecting 90.00): 91.169636
Group 1 : Average length: 2.320682
Init Loss = 0.7501351
Final Loss = 0.6235941
Fair dummies test (classification score), p-value: 0.5564435564435565
experiment = 5
Coverage 0 = 0.9023827824750192
Coverage 1 = 0.9116963594113091
Length 0 = 2.272867025365104
Length 1 = 2.3206816421378775
Prediction Error = 0.6655092592592593
p_val = 0.5564435564435565
HGR_linear_model
Num experiments 05 | Avg. Pred Err = 0.4151 | Avg Length 0 = 1.5255 | Avg Length 1 = 1.4966 | Avg Coverage 0 = 0.8959 | Avg Coverage 1 = 0.9011 | Avg p_val = 0.3774 | min p_val = 0.0589
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4654603 ACC = 0.2846668381785439
mu = 0.98 Loss = 0.7216458 ACC = 0.6604064831489581
Group 0 : Percentage in the range (expecting 90.00): 90.206580
Group 0 : Average length: 1.283091
Group 1 : Percentage in the range (expecting 90.00): 89.727626
Group 1 : Average length: 1.295720
Init Loss = 0.7169718
Final Loss = 0.61250526
Fair dummies test (classification score), p-value: 0.5514485514485514
experiment = 6
Coverage 0 = 0.9020657995409335
Coverage 1 = 0.8972762645914397
Length 0 = 1.2830910482019893
Length 1 = 1.2957198443579767
Prediction Error = 0.3310185185185185
p_val = 0.5514485514485514
HGR_linear_model
Num experiments 06 | Avg. Pred Err = 0.4011 | Avg Length 0 = 1.4851 | Avg Length 1 = 1.4631 | Avg Coverage 0 = 0.8969 | Avg Coverage 1 = 0.9005 | Avg p_val = 0.4064 | min p_val = 0.0589
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.7375939 ACC = 0.15924877797787496
mu = 0.98 Loss = 1.0923179 ACC = 0.331232312837664
Group 0 : Percentage in the range (expecting 90.00): 90.293454
Group 0 : Average length: 2.335591
Group 1 : Percentage in the range (expecting 90.00): 90.340459
Group 1 : Average length: 2.318290
Init Loss = 0.68527246
Final Loss = 0.62674016
Fair dummies test (classification score), p-value: 0.016983016983016984
experiment = 7
Coverage 0 = 0.9029345372460497
Coverage 1 = 0.9034045922406968
Length 0 = 2.3355906696764483
Length 1 = 2.318289786223278
Prediction Error = 0.6655092592592593
p_val = 0.016983016983016984
HGR_linear_model
Num experiments 07 | Avg. Pred Err = 0.4389 | Avg Length 0 = 1.6066 | Avg Length 1 = 1.5853 | Avg Coverage 0 = 0.8978 | Avg Coverage 1 = 0.9009 | Avg p_val = 0.3508 | min p_val = 0.0170
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.5887978 ACC = 0.2729611525598148
mu = 0.98 Loss = 1.1231365 ACC = 0.312194494468742
Group 0 : Percentage in the range (expecting 90.00): 92.283710
Group 0 : Average length: 2.363991
Group 1 : Percentage in the range (expecting 90.00): 90.909091
Group 1 : Average length: 2.271199
Init Loss = 0.7618549
Final Loss = 0.6208351
Fair dummies test (classification score), p-value: 0.1838161838161838
experiment = 8
Coverage 0 = 0.9228371005455963
Coverage 1 = 0.9090909090909091
Length 0 = 2.363990646921278
Length 1 = 2.2711993888464477
Prediction Error = 0.6851851851851851
p_val = 0.1838161838161838
HGR_linear_model
Num experiments 08 | Avg. Pred Err = 0.4697 | Avg Length 0 = 1.7013 | Avg Length 1 = 1.6710 | Avg Coverage 0 = 0.9009 | Avg Coverage 1 = 0.9019 | Avg p_val = 0.3299 | min p_val = 0.0170
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.6174039 ACC = 0.1875482377154618
mu = 0.98 Loss = 0.6729093 ACC = 0.639310522253666
Group 0 : Percentage in the range (expecting 90.00): 92.467333
Group 0 : Average length: 1.359723
Group 1 : Percentage in the range (expecting 90.00): 88.690937
Group 1 : Average length: 1.262587
Init Loss = 0.66419137
Final Loss = 0.5958685
Fair dummies test (classification score), p-value: 0.3356643356643357
experiment = 9
Coverage 0 = 0.92467332820907
Coverage 1 = 0.8869093725793958
Length 0 = 1.3597232897770946
Length 1 = 1.262587141750581
Prediction Error = 0.33526234567901236
p_val = 0.3356643356643357
HGR_linear_model
Num experiments 09 | Avg. Pred Err = 0.4547 | Avg Length 0 = 1.6633 | Avg Length 1 = 1.6257 | Avg Coverage 0 = 0.9036 | Avg Coverage 1 = 0.9002 | Avg p_val = 0.3306 | min p_val = 0.0170
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3831065 ACC = 0.34190892719320815
mu = 0.98 Loss = 0.68492204 ACC = 0.6629791613069205
Group 0 : Percentage in the range (expecting 90.00): 91.006098
Group 0 : Average length: 1.307927
Group 1 : Percentage in the range (expecting 90.00): 90.468750
Group 1 : Average length: 1.278906
Init Loss = 0.72662115
Final Loss = 0.59882075
Fair dummies test (classification score), p-value: 0.23176823176823177
experiment = 10
Coverage 0 = 0.9100609756097561
Coverage 1 = 0.9046875
Length 0 = 1.3079268292682926
Length 1 = 1.27890625
Prediction Error = 0.33217592592592593
p_val = 0.23176823176823177
HGR_linear_model
Num experiments 10 | Avg. Pred Err = 0.4425 | Avg Length 0 = 1.6278 | Avg Length 1 = 1.5910 | Avg Coverage 0 = 0.9042 | Avg Coverage 1 = 0.9007 | Avg p_val = 0.3207 | min p_val = 0.0170
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.6352861 ACC = 0.1628505273990224
mu = 0.98 Loss = 0.8059756 ACC = 0.7469771031643941
Group 0 : Percentage in the range (expecting 90.00): 88.348765
Group 0 : Average length: 1.209877
Group 1 : Percentage in the range (expecting 90.00): 91.435185
Group 1 : Average length: 1.279321
Init Loss = 0.7056613
Final Loss = 0.6504872
Fair dummies test (classification score), p-value: 0.002997002997002997
experiment = 11
Coverage 0 = 0.8834876543209876
Coverage 1 = 0.9143518518518519
Length 0 = 1.2098765432098766
Length 1 = 1.279320987654321
Prediction Error = 0.24845679012345678
p_val = 0.002997002997002997
HGR_linear_model
Num experiments 11 | Avg. Pred Err = 0.4248 | Avg Length 0 = 1.5898 | Avg Length 1 = 1.5627 | Avg Coverage 0 = 0.9023 | Avg Coverage 1 = 0.9019 | Avg p_val = 0.2918 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.629236 ACC = 0.2244661692822228
mu = 0.98 Loss = 0.6481876 ACC = 0.6443272446616928
Group 0 : Percentage in the range (expecting 90.00): 90.993072
Group 0 : Average length: 1.386451
Group 1 : Percentage in the range (expecting 90.00): 90.641918
Group 1 : Average length: 1.275329
Init Loss = 0.7164685
Final Loss = 0.5828518
Fair dummies test (classification score), p-value: 0.10989010989010989
experiment = 12
Coverage 0 = 0.9099307159353349
Coverage 1 = 0.9064191802010828
Length 0 = 1.386451116243264
Length 1 = 1.2753286929621037
Prediction Error = 0.3441358024691358
p_val = 0.10989010989010989
HGR_linear_model
Num experiments 12 | Avg. Pred Err = 0.4181 | Avg Length 0 = 1.5728 | Avg Length 1 = 1.5387 | Avg Coverage 0 = 0.9030 | Avg Coverage 1 = 0.9023 | Avg p_val = 0.2766 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.626913 ACC = 0.15281708258296886
mu = 0.98 Loss = 0.7172621 ACC = 0.8017751479289941
Group 0 : Percentage in the range (expecting 90.00): 89.696071
Group 0 : Average length: 1.258710
Group 1 : Percentage in the range (expecting 90.00): 90.024135
Group 1 : Average length: 1.219630
Init Loss = 0.70501155
Final Loss = 0.6271645
Fair dummies test (classification score), p-value: 0.1798201798201798
experiment = 13
Coverage 0 = 0.8969607116382505
Coverage 1 = 0.9002413515687852
Length 0 = 1.2587101556708673
Length 1 = 1.2196299275945293
Prediction Error = 0.19945987654320985
p_val = 0.1798201798201798
HGR_linear_model
Num experiments 13 | Avg. Pred Err = 0.4013 | Avg Length 0 = 1.5487 | Avg Length 1 = 1.5142 | Avg Coverage 0 = 0.9025 | Avg Coverage 1 = 0.9021 | Avg p_val = 0.2692 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4323092 ACC = 0.2550810393619758
mu = 0.98 Loss = 0.6566425 ACC = 0.6448417802932853
Group 0 : Percentage in the range (expecting 90.00): 89.652510
Group 0 : Average length: 1.357529
Group 1 : Percentage in the range (expecting 90.00): 91.904395
Group 1 : Average length: 1.304549
Init Loss = 0.7368039
Final Loss = 0.58569884
Fair dummies test (classification score), p-value: 0.7262737262737263
experiment = 14
Coverage 0 = 0.8965250965250965
Coverage 1 = 0.9190439475713185
Length 0 = 1.3575289575289575
Length 1 = 1.3045489591364687
Prediction Error = 0.3491512345679012
p_val = 0.7262737262737263
HGR_linear_model
Num experiments 14 | Avg. Pred Err = 0.3976 | Avg Length 0 = 1.5350 | Avg Length 1 = 1.4992 | Avg Coverage 0 = 0.9021 | Avg Coverage 1 = 0.9034 | Avg p_val = 0.3018 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.5305206 ACC = 0.26048366349369695
mu = 0.98 Loss = 0.6515196 ACC = 0.6640082325701054
Group 0 : Percentage in the range (expecting 90.00): 89.898990
Group 0 : Average length: 1.277389
Group 1 : Percentage in the range (expecting 90.00): 89.348659
Group 1 : Average length: 1.296552
Init Loss = 0.70616114
Final Loss = 0.58409953
Fair dummies test (classification score), p-value: 0.3726273726273726
experiment = 15
Coverage 0 = 0.898989898989899
Coverage 1 = 0.8934865900383142
Length 0 = 1.2773892773892774
Length 1 = 1.296551724137931
Prediction Error = 0.34066358024691357
p_val = 0.3726273726273726
HGR_linear_model
Num experiments 15 | Avg. Pred Err = 0.3938 | Avg Length 0 = 1.5179 | Avg Length 1 = 1.4857 | Avg Coverage 0 = 0.9019 | Avg Coverage 1 = 0.9027 | Avg p_val = 0.3066 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.7595881 ACC = 0.10162078723951634
mu = 0.98 Loss = 1.0737789 ACC = 0.33097504502186775
Group 0 : Percentage in the range (expecting 90.00): 89.249012
Group 0 : Average length: 2.337549
Group 1 : Percentage in the range (expecting 90.00): 89.751319
Group 1 : Average length: 2.344386
Init Loss = 0.6794043
Final Loss = 0.62446314
Fair dummies test (classification score), p-value: 0.1928071928071928
experiment = 16
Coverage 0 = 0.892490118577075
Coverage 1 = 0.8975131876412962
Length 0 = 2.3375494071146243
Length 1 = 2.3443858327053504
Prediction Error = 0.6786265432098766
p_val = 0.1928071928071928
HGR_linear_model
Num experiments 16 | Avg. Pred Err = 0.4116 | Avg Length 0 = 1.5691 | Avg Length 1 = 1.5394 | Avg Coverage 0 = 0.9013 | Avg Coverage 1 = 0.9024 | Avg p_val = 0.2995 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.5234965 ACC = 0.2678157962438899
mu = 0.98 Loss = 0.6677545 ACC = 0.6399536917931566
Group 0 : Percentage in the range (expecting 90.00): 92.083013
Group 0 : Average length: 1.363566
Group 1 : Percentage in the range (expecting 90.00): 89.930287
Group 1 : Average length: 1.271108
Init Loss = 0.6831539
Final Loss = 0.5873816
Fair dummies test (classification score), p-value: 0.027972027972027972
experiment = 17
Coverage 0 = 0.9208301306687163
Coverage 1 = 0.8993028659953525
Length 0 = 1.363566487317448
Length 1 = 1.2711076684740512
Prediction Error = 0.3452932098765432
p_val = 0.027972027972027972
HGR_linear_model
Num experiments 17 | Avg. Pred Err = 0.4077 | Avg Length 0 = 1.5570 | Avg Length 1 = 1.5236 | Avg Coverage 0 = 0.9024 | Avg Coverage 1 = 0.9022 | Avg p_val = 0.2835 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.5389457 ACC = 0.2191921790583998
mu = 0.98 Loss = 1.0968673 ACC = 0.3107795214818626
Group 0 : Percentage in the range (expecting 90.00): 87.586207
Group 0 : Average length: 2.336398
Group 1 : Percentage in the range (expecting 90.00): 90.909091
Group 1 : Average length: 2.274281
Init Loss = 0.69525605
Final Loss = 0.6335957
Fair dummies test (classification score), p-value: 0.2857142857142857
experiment = 18
Coverage 0 = 0.8758620689655172
Coverage 1 = 0.9090909090909091
Length 0 = 2.33639846743295
Length 1 = 2.2742812742812744
Prediction Error = 0.7002314814814814
p_val = 0.2857142857142857
HGR_linear_model
Num experiments 18 | Avg. Pred Err = 0.4239 | Avg Length 0 = 1.6003 | Avg Length 1 = 1.5653 | Avg Coverage 0 = 0.9010 | Avg Coverage 1 = 0.9026 | Avg p_val = 0.2836 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.8941206 ACC = 0.06959094417288397
mu = 0.98 Loss = 1.2649822 ACC = 0.0
Group 0 : Percentage in the range (expecting 90.00): 90.000000
Group 0 : Average length: 2.933594
Group 1 : Percentage in the range (expecting 90.00): 89.024390
Group 1 : Average length: 2.910061
Init Loss = 0.69052416
Final Loss = 0.598492
Fair dummies test (classification score), p-value: 0.6613386613386614
experiment = 19
Coverage 0 = 0.9
Coverage 1 = 0.8902439024390244
Length 0 = 2.93359375
Length 1 = 2.910060975609756
Prediction Error = 1.0
p_val = 0.6613386613386614
HGR_linear_model
Num experiments 19 | Avg. Pred Err = 0.4543 | Avg Length 0 = 1.6705 | Avg Length 1 = 1.6361 | Avg Coverage 0 = 0.9009 | Avg Coverage 1 = 0.9019 | Avg p_val = 0.3035 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.7484648 ACC = 0.1692822227939285
mu = 0.98 Loss = 1.0922378 ACC = 0.31978389503473115
Group 0 : Percentage in the range (expecting 90.00): 92.307692
Group 0 : Average length: 2.387692
Group 1 : Percentage in the range (expecting 90.00): 89.164087
Group 1 : Average length: 2.261610
Init Loss = 0.6771437
Final Loss = 0.6271164
Fair dummies test (classification score), p-value: 0.6853146853146853
experiment = 20
Coverage 0 = 0.9230769230769231
Coverage 1 = 0.891640866873065
Length 0 = 2.3876923076923076
Length 1 = 2.261609907120743
Prediction Error = 0.7013888888888888
p_val = 0.6853146853146853
HGR_linear_model
Num experiments 20 | Avg. Pred Err = 0.4666 | Avg Length 0 = 1.7063 | Avg Length 1 = 1.6673 | Avg Coverage 0 = 0.9020 | Avg Coverage 1 = 0.9014 | Avg p_val = 0.3226 | min p_val = 0.0030
======== Done =========
nursery
HGR
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.508576 ACC = 0.16426550038590174
mu = 0.98 Loss = 0.58395135 ACC = 0.7139181888345768
Group 0 : Percentage in the range (expecting 90.00): 87.577640
Group 0 : Average length: 1.397516
Group 1 : Percentage in the range (expecting 90.00): 88.650307
Group 1 : Average length: 1.429448
Init Loss = 0.7123772
Final Loss = 0.5183176
Fair dummies test (classification score), p-value: 0.3176823176823177
experiment = 1
Coverage 0 = 0.8757763975155279
Coverage 1 = 0.8865030674846626
Length 0 = 1.3975155279503106
Length 1 = 1.4294478527607362
Prediction Error = 0.2920524691358025
p_val = 0.3176823176823177
HGR_deep_model
Num experiments 01 | Avg. Pred Err = 0.2921 | Avg Length 0 = 1.3975 | Avg Length 1 = 1.4294 | Avg Coverage 0 = 0.8758 | Avg Coverage 1 = 0.8865 | Avg p_val = 0.3177 | min p_val = 0.3177
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4386729 ACC = 0.23257010547980447
mu = 0.98 Loss = 0.59067374 ACC = 0.7068433239001801
Group 0 : Percentage in the range (expecting 90.00): 91.864139
Group 0 : Average length: 1.525276
Group 1 : Percentage in the range (expecting 90.00): 90.346908
Group 1 : Average length: 1.427602
Init Loss = 0.6949436
Final Loss = 0.51935136
Fair dummies test (classification score), p-value: 0.7732267732267732
experiment = 2
Coverage 0 = 0.9186413902053713
Coverage 1 = 0.9034690799396682
Length 0 = 1.5252764612954186
Length 1 = 1.4276018099547512
Prediction Error = 0.30632716049382713
p_val = 0.7732267732267732
HGR_deep_model
Num experiments 02 | Avg. Pred Err = 0.2992 | Avg Length 0 = 1.4614 | Avg Length 1 = 1.4285 | Avg Coverage 0 = 0.8972 | Avg Coverage 1 = 0.8950 | Avg p_val = 0.5455 | min p_val = 0.3177
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.392087 ACC = 0.3133521996398251
mu = 0.98 Loss = 0.5954808 ACC = 0.6866478003601749
Group 0 : Percentage in the range (expecting 90.00): 88.632873
Group 0 : Average length: 1.465438
Group 1 : Percentage in the range (expecting 90.00): 90.465116
Group 1 : Average length: 1.455039
Init Loss = 0.7204763
Final Loss = 0.52430147
Fair dummies test (classification score), p-value: 0.003996003996003996
experiment = 3
Coverage 0 = 0.8863287250384024
Coverage 1 = 0.9046511627906977
Length 0 = 1.4654377880184333
Length 1 = 1.4550387596899226
Prediction Error = 0.31558641975308643
p_val = 0.003996003996003996
HGR_deep_model
Num experiments 03 | Avg. Pred Err = 0.3047 | Avg Length 0 = 1.4627 | Avg Length 1 = 1.4374 | Avg Coverage 0 = 0.8936 | Avg Coverage 1 = 0.8982 | Avg p_val = 0.3650 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4891453 ACC = 0.18253151530743503
mu = 0.98 Loss = 1.1909463 ACC = 0.31811165423205556
Group 0 : Percentage in the range (expecting 90.00): 89.657854
Group 0 : Average length: 2.481337
Group 1 : Percentage in the range (expecting 90.00): 90.658499
Group 1 : Average length: 2.441807
Init Loss = 0.6876751
Final Loss = 0.6035719
Fair dummies test (classification score), p-value: 0.1018981018981019
experiment = 4
Coverage 0 = 0.8965785381026439
Coverage 1 = 0.9065849923430321
Length 0 = 2.481337480559876
Length 1 = 2.4418070444104134
Prediction Error = 0.689429012345679
p_val = 0.1018981018981019
HGR_deep_model
Num experiments 04 | Avg. Pred Err = 0.4008 | Avg Length 0 = 1.7174 | Avg Length 1 = 1.6885 | Avg Coverage 0 = 0.8943 | Avg Coverage 1 = 0.9003 | Avg p_val = 0.2992 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3638734 ACC = 0.30923591458708516
mu = 0.98 Loss = 0.5541203 ACC = 0.7418317468484693
Group 0 : Percentage in the range (expecting 90.00): 90.238278
Group 0 : Average length: 1.370484
Group 1 : Percentage in the range (expecting 90.00): 90.627421
Group 1 : Average length: 1.356313
Init Loss = 0.67184544
Final Loss = 0.4694091
Fair dummies test (classification score), p-value: 0.22077922077922077
experiment = 5
Coverage 0 = 0.9023827824750192
Coverage 1 = 0.9062742060418281
Length 0 = 1.3704842428900845
Length 1 = 1.3563129357087529
Prediction Error = 0.2372685185185185
p_val = 0.22077922077922077
HGR_deep_model
Num experiments 05 | Avg. Pred Err = 0.3681 | Avg Length 0 = 1.6480 | Avg Length 1 = 1.6220 | Avg Coverage 0 = 0.8959 | Avg Coverage 1 = 0.9015 | Avg p_val = 0.2835 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.328248 ACC = 0.3416516593774119
mu = 0.98 Loss = 0.55579144 ACC = 0.7567532801646514
Group 0 : Percentage in the range (expecting 90.00): 90.359602
Group 0 : Average length: 1.377200
Group 1 : Percentage in the range (expecting 90.00): 88.715953
Group 1 : Average length: 1.325292
Init Loss = 0.71533597
Final Loss = 0.46991703
Fair dummies test (classification score), p-value: 0.5714285714285714
experiment = 6
Coverage 0 = 0.9035960214231064
Coverage 1 = 0.8871595330739299
Length 0 = 1.3771996939556235
Length 1 = 1.3252918287937743
Prediction Error = 0.23996913580246915
p_val = 0.5714285714285714
HGR_deep_model
Num experiments 06 | Avg. Pred Err = 0.3468 | Avg Length 0 = 1.6029 | Avg Length 1 = 1.5726 | Avg Coverage 0 = 0.8972 | Avg Coverage 1 = 0.8991 | Avg p_val = 0.3315 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4139514 ACC = 0.24530486236171856
mu = 0.98 Loss = 1.168348 ACC = 0.31373810136351943
Group 0 : Percentage in the range (expecting 90.00): 88.939052
Group 0 : Average length: 2.495862
Group 1 : Percentage in the range (expecting 90.00): 92.240697
Group 1 : Average length: 2.428345
Init Loss = 0.71196175
Final Loss = 0.60970324
Fair dummies test (classification score), p-value: 0.1838161838161838
experiment = 7
Coverage 0 = 0.8893905191873589
Coverage 1 = 0.9224069675376089
Length 0 = 2.4958615500376222
Length 1 = 2.428345209817894
Prediction Error = 0.6863425925925926
p_val = 0.1838161838161838
HGR_deep_model
Num experiments 07 | Avg. Pred Err = 0.3953 | Avg Length 0 = 1.7304 | Avg Length 1 = 1.6948 | Avg Coverage 0 = 0.8961 | Avg Coverage 1 = 0.9024 | Avg p_val = 0.3104 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4750477 ACC = 0.21237458193979933
mu = 0.98 Loss = 1.2213405 ACC = 0.3124517622845382
Group 0 : Percentage in the range (expecting 90.00): 90.958691
Group 0 : Average length: 2.488698
Group 1 : Percentage in the range (expecting 90.00): 92.436975
Group 1 : Average length: 2.476700
Init Loss = 0.6826698
Final Loss = 0.5980418
Fair dummies test (classification score), p-value: 0.6283716283716284
experiment = 8
Coverage 0 = 0.9095869056897895
Coverage 1 = 0.9243697478991597
Length 0 = 2.4886983632112236
Length 1 = 2.476699770817418
Prediction Error = 0.6847993827160495
p_val = 0.6283716283716284
HGR_deep_model
Num experiments 08 | Avg. Pred Err = 0.4315 | Avg Length 0 = 1.8252 | Avg Length 1 = 1.7926 | Avg Coverage 0 = 0.8978 | Avg Coverage 1 = 0.9052 | Avg p_val = 0.3501 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4923664 ACC = 0.16014921533316182
mu = 0.98 Loss = 1.2134589 ACC = 0.3089786467712889
Group 0 : Percentage in the range (expecting 90.00): 93.389700
Group 0 : Average length: 2.495772
Group 1 : Percentage in the range (expecting 90.00): 89.775368
Group 1 : Average length: 2.402789
Init Loss = 0.74909264
Final Loss = 0.6033028
Fair dummies test (classification score), p-value: 0.21678321678321677
experiment = 9
Coverage 0 = 0.9338970023059185
Coverage 1 = 0.8977536793183578
Length 0 = 2.495772482705611
Length 1 = 2.40278853601859
Prediction Error = 0.6766975308641976
p_val = 0.21678321678321677
HGR_deep_model
Num experiments 09 | Avg. Pred Err = 0.4587 | Avg Length 0 = 1.8997 | Avg Length 1 = 1.8604 | Avg Coverage 0 = 0.9018 | Avg Coverage 1 = 0.9044 | Avg p_val = 0.3353 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3703926 ACC = 0.3156676099819912
mu = 0.98 Loss = 0.58652025 ACC = 0.685747363004888
Group 0 : Percentage in the range (expecting 90.00): 91.234756
Group 0 : Average length: 1.530488
Group 1 : Percentage in the range (expecting 90.00): 92.031250
Group 1 : Average length: 1.487500
Init Loss = 0.69932306
Final Loss = 0.5053917
Fair dummies test (classification score), p-value: 0.2707292707292707
experiment = 10
Coverage 0 = 0.9123475609756098
Coverage 1 = 0.9203125
Length 0 = 1.5304878048780488
Length 1 = 1.4875
Prediction Error = 0.3213734567901234
p_val = 0.2707292707292707
HGR_deep_model
Num experiments 10 | Avg. Pred Err = 0.4450 | Avg Length 0 = 1.8628 | Avg Length 1 = 1.8231 | Avg Coverage 0 = 0.9029 | Avg Coverage 1 = 0.9059 | Avg p_val = 0.3289 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.533027 ACC = 0.16400823257010547
mu = 0.98 Loss = 0.56250614 ACC = 0.7504502186776434
Group 0 : Percentage in the range (expecting 90.00): 89.814815
Group 0 : Average length: 1.395833
Group 1 : Percentage in the range (expecting 90.00): 91.358025
Group 1 : Average length: 1.403549
Init Loss = 0.68323326
Final Loss = 0.48593763
Fair dummies test (classification score), p-value: 0.5764235764235764
experiment = 11
Coverage 0 = 0.8981481481481481
Coverage 1 = 0.9135802469135802
Length 0 = 1.3958333333333333
Length 1 = 1.4035493827160495
Prediction Error = 0.24845679012345678
p_val = 0.5764235764235764
HGR_deep_model
Num experiments 11 | Avg. Pred Err = 0.4271 | Avg Length 0 = 1.8204 | Avg Length 1 = 1.7849 | Avg Coverage 0 = 0.9024 | Avg Coverage 1 = 0.9066 | Avg p_val = 0.3514 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3818111 ACC = 0.25212245948031903
mu = 0.98 Loss = 0.5752843 ACC = 0.6706971957808078
Group 0 : Percentage in the range (expecting 90.00): 91.608930
Group 0 : Average length: 1.523480
Group 1 : Percentage in the range (expecting 90.00): 89.017788
Group 1 : Average length: 1.457850
Init Loss = 0.6806521
Final Loss = 0.49554718
Fair dummies test (classification score), p-value: 0.008991008991008992
experiment = 12
Coverage 0 = 0.9160892994611239
Coverage 1 = 0.8901778808971385
Length 0 = 1.523479599692071
Length 1 = 1.4578499613302398
Prediction Error = 0.32793209876543206
p_val = 0.008991008991008992
HGR_deep_model
Num experiments 12 | Avg. Pred Err = 0.4189 | Avg Length 0 = 1.7956 | Avg Length 1 = 1.7577 | Avg Coverage 0 = 0.9036 | Avg Coverage 1 = 0.9053 | Avg p_val = 0.3228 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4566681 ACC = 0.2297401595060458
mu = 0.98 Loss = 0.5947414 ACC = 0.7126318497555956
Group 0 : Percentage in the range (expecting 90.00): 89.177168
Group 0 : Average length: 1.407709
Group 1 : Percentage in the range (expecting 90.00): 91.069992
Group 1 : Average length: 1.412711
Init Loss = 0.66381913
Final Loss = 0.5252175
Fair dummies test (classification score), p-value: 0.12487512487512488
experiment = 13
Coverage 0 = 0.8917716827279466
Coverage 1 = 0.910699919549477
Length 0 = 1.407709414381023
Length 1 = 1.412711182622687
Prediction Error = 0.2889660493827161
p_val = 0.12487512487512488
HGR_deep_model
Num experiments 13 | Avg. Pred Err = 0.4089 | Avg Length 0 = 1.7658 | Avg Length 1 = 1.7311 | Avg Coverage 0 = 0.9027 | Avg Coverage 1 = 0.9057 | Avg p_val = 0.3076 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4696867 ACC = 0.2316696681245176
mu = 0.98 Loss = 0.5958535 ACC = 0.6944944687419604
Group 0 : Percentage in the range (expecting 90.00): 89.961390
Group 0 : Average length: 1.405405
Group 1 : Percentage in the range (expecting 90.00): 89.899769
Group 1 : Average length: 1.428682
Init Loss = 0.67247
Final Loss = 0.5271704
Fair dummies test (classification score), p-value: 0.4355644355644356
experiment = 14
Coverage 0 = 0.8996138996138996
Coverage 1 = 0.8989976869699307
Length 0 = 1.4054054054054055
Length 1 = 1.4286815728604472
Prediction Error = 0.30208333333333337
p_val = 0.4355644355644356
HGR_deep_model
Num experiments 14 | Avg. Pred Err = 0.4012 | Avg Length 0 = 1.7400 | Avg Length 1 = 1.7095 | Avg Coverage 0 = 0.9024 | Avg Coverage 1 = 0.9052 | Avg p_val = 0.3168 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3258373 ACC = 0.3605608438384358
mu = 0.98 Loss = 0.5621371 ACC = 0.7167481348083354
Group 0 : Percentage in the range (expecting 90.00): 90.831391
Group 0 : Average length: 1.468531
Group 1 : Percentage in the range (expecting 90.00): 90.344828
Group 1 : Average length: 1.416858
Init Loss = 0.7461771
Final Loss = 0.50752366
Fair dummies test (classification score), p-value: 0.02097902097902098
experiment = 15
Coverage 0 = 0.9083139083139083
Coverage 1 = 0.903448275862069
Length 0 = 1.4685314685314685
Length 1 = 1.4168582375478926
Prediction Error = 0.28587962962962965
p_val = 0.02097902097902098
HGR_deep_model
Num experiments 15 | Avg. Pred Err = 0.3935 | Avg Length 0 = 1.7219 | Avg Length 1 = 1.6900 | Avg Coverage 0 = 0.9028 | Avg Coverage 1 = 0.9051 | Avg p_val = 0.2970 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.3800976 ACC = 0.3228711088242861
mu = 0.98 Loss = 0.5648338 ACC = 0.7546951376382814
Group 0 : Percentage in the range (expecting 90.00): 89.328063
Group 0 : Average length: 1.384980
Group 1 : Percentage in the range (expecting 90.00): 91.032404
Group 1 : Average length: 1.363225
Init Loss = 0.72851706
Final Loss = 0.49975097
Fair dummies test (classification score), p-value: 0.3626373626373626
experiment = 16
Coverage 0 = 0.8932806324110671
Coverage 1 = 0.9103240391861341
Length 0 = 1.3849802371541502
Length 1 = 1.3632253202712887
Prediction Error = 0.2550154320987654
p_val = 0.3626373626373626
HGR_deep_model
Num experiments 16 | Avg. Pred Err = 0.3849 | Avg Length 0 = 1.7009 | Avg Length 1 = 1.6696 | Avg Coverage 0 = 0.9022 | Avg Coverage 1 = 0.9054 | Avg p_val = 0.3011 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4418753 ACC = 0.2480061744275791
mu = 0.98 Loss = 0.6022898 ACC = 0.6947517365577566
Group 0 : Percentage in the range (expecting 90.00): 91.006918
Group 0 : Average length: 1.427364
Group 1 : Percentage in the range (expecting 90.00): 88.613478
Group 1 : Average length: 1.392719
Init Loss = 0.696046
Final Loss = 0.51244116
Fair dummies test (classification score), p-value: 0.3926073926073926
experiment = 17
Coverage 0 = 0.9100691775557264
Coverage 1 = 0.8861347792408986
Length 0 = 1.4273635664873174
Length 1 = 1.3927188226181255
Prediction Error = 0.30015432098765427
p_val = 0.3926073926073926
HGR_deep_model
Num experiments 17 | Avg. Pred Err = 0.3799 | Avg Length 0 = 1.6848 | Avg Length 1 = 1.6533 | Avg Coverage 0 = 0.9027 | Avg Coverage 1 = 0.9043 | Avg p_val = 0.3065 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4517263 ACC = 0.23784409570362747
mu = 0.98 Loss = 0.6013619 ACC = 0.6998970928736815
Group 0 : Percentage in the range (expecting 90.00): 87.892720
Group 0 : Average length: 1.368582
Group 1 : Percentage in the range (expecting 90.00): 90.753691
Group 1 : Average length: 1.427350
Init Loss = 0.72823435
Final Loss = 0.5339018
Fair dummies test (classification score), p-value: 0.5304695304695305
experiment = 18
Coverage 0 = 0.878927203065134
Coverage 1 = 0.9075369075369075
Length 0 = 1.3685823754789272
Length 1 = 1.4273504273504274
Prediction Error = 0.2943672839506173
p_val = 0.5304695304695305
HGR_deep_model
Num experiments 18 | Avg. Pred Err = 0.3752 | Avg Length 0 = 1.6672 | Avg Length 1 = 1.6408 | Avg Coverage 0 = 0.9014 | Avg Coverage 1 = 0.9045 | Avg p_val = 0.3190 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.4527977 ACC = 0.2316696681245176
mu = 0.98 Loss = 0.759226 ACC = 0.7396449704142012
Group 0 : Percentage in the range (expecting 90.00): 89.140625
Group 0 : Average length: 1.387500
Group 1 : Percentage in the range (expecting 90.00): 88.719512
Group 1 : Average length: 1.380335
Init Loss = 0.69600844
Final Loss = 0.6302876
Fair dummies test (classification score), p-value: 0.7242757242757243
experiment = 19
Coverage 0 = 0.89140625
Coverage 1 = 0.8871951219512195
Length 0 = 1.3875
Length 1 = 1.3803353658536586
Prediction Error = 0.2442129629629629
p_val = 0.7242757242757243
HGR_deep_model
Num experiments 19 | Avg. Pred Err = 0.3683 | Avg Length 0 = 1.6525 | Avg Length 1 = 1.6271 | Avg Coverage 0 = 0.9008 | Avg Coverage 1 = 0.9036 | Avg p_val = 0.3403 | min p_val = 0.0040
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Init : Loss = 1.5097257 ACC = 0.16722408026755853
mu = 0.98 Loss = 1.1961561 ACC = 0.3218420375611011
Group 0 : Percentage in the range (expecting 90.00): 90.615385
Group 0 : Average length: 2.497692
Group 1 : Percentage in the range (expecting 90.00): 90.557276
Group 1 : Average length: 2.415635
Init Loss = 0.6311261
Final Loss = 0.6017415
Fair dummies test (classification score), p-value: 0.3256743256743257
experiment = 20
Coverage 0 = 0.9061538461538462
Coverage 1 = 0.9055727554179567
Length 0 = 2.497692307692308
Length 1 = 2.4156346749226008
Prediction Error = 0.7002314814814814
p_val = 0.3256743256743257
HGR_deep_model
Num experiments 20 | Avg. Pred Err = 0.3849 | Avg Length 0 = 1.6948 | Avg Length 1 = 1.6665 | Avg Coverage 0 = 0.9011 | Avg Coverage 1 = 0.9037 | Avg p_val = 0.3396 | min p_val = 0.0040
======== Done =========
nursery
AdversarialDebiasing
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.285714
Group 0 : Average length: 1.423913
Group 1 : Percentage in the range (expecting 90.00): 90.184049
Group 1 : Average length: 1.408742
Init Loss = 0.6784908
Final Loss = 0.42227367
Fair dummies test (classification score), p-value: 0.27372627372627373
experiment = 1
Coverage 0 = 0.8928571428571429
Coverage 1 = 0.901840490797546
Length 0 = 1.423913043478261
Length 1 = 1.4087423312883436
Prediction Error = 0.32986111111111116
p_val = 0.27372627372627373
AdversarialDebiasing_deep_model
Num experiments 01 | Avg. Pred Err = 0.3299 | Avg Length 0 = 1.4239 | Avg Length 1 = 1.4087 | Avg Coverage 0 = 0.8929 | Avg Coverage 1 = 0.9018 | Avg p_val = 0.2737 | min p_val = 0.2737
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.521327
Group 0 : Average length: 1.537125
Group 1 : Percentage in the range (expecting 90.00): 90.346908
Group 1 : Average length: 1.470588
Init Loss = 0.6972718
Final Loss = 0.36195955
Fair dummies test (classification score), p-value: 0.46553446553446554
experiment = 2
Coverage 0 = 0.9052132701421801
Coverage 1 = 0.9034690799396682
Length 0 = 1.537124802527646
Length 1 = 1.4705882352941178
Prediction Error = 0.3472222222222222
p_val = 0.46553446553446554
AdversarialDebiasing_deep_model
Num experiments 02 | Avg. Pred Err = 0.3385 | Avg Length 0 = 1.4805 | Avg Length 1 = 1.4397 | Avg Coverage 0 = 0.8990 | Avg Coverage 1 = 0.9027 | Avg p_val = 0.3696 | min p_val = 0.2737
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.784946
Group 0 : Average length: 1.469278
Group 1 : Percentage in the range (expecting 90.00): 90.232558
Group 1 : Average length: 1.434884
Init Loss = 0.6782674
Final Loss = 0.33633506
Fair dummies test (classification score), p-value: 0.01898101898101898
experiment = 3
Coverage 0 = 0.8978494623655914
Coverage 1 = 0.9023255813953488
Length 0 = 1.4692780337941629
Length 1 = 1.4348837209302325
Prediction Error = 0.3599537037037037
p_val = 0.01898101898101898
AdversarialDebiasing_deep_model
Num experiments 03 | Avg. Pred Err = 0.3457 | Avg Length 0 = 1.4768 | Avg Length 1 = 1.4381 | Avg Coverage 0 = 0.8986 | Avg Coverage 1 = 0.9025 | Avg p_val = 0.2527 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.813375
Group 0 : Average length: 1.444790
Group 1 : Percentage in the range (expecting 90.00): 91.424196
Group 1 : Average length: 1.419602
Init Loss = 0.72164404
Final Loss = 0.4497984
Fair dummies test (classification score), p-value: 0.4205794205794206
experiment = 4
Coverage 0 = 0.8981337480559876
Coverage 1 = 0.9142419601837672
Length 0 = 1.4447900466562986
Length 1 = 1.4196018376722819
Prediction Error = 0.33912037037037035
p_val = 0.4205794205794206
AdversarialDebiasing_deep_model
Num experiments 04 | Avg. Pred Err = 0.3440 | Avg Length 0 = 1.4688 | Avg Length 1 = 1.4335 | Avg Coverage 0 = 0.8985 | Avg Coverage 1 = 0.9055 | Avg p_val = 0.2947 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.161414
Group 0 : Average length: 1.460415
Group 1 : Percentage in the range (expecting 90.00): 90.007746
Group 1 : Average length: 1.450039
Init Loss = 0.7517055
Final Loss = 0.380398
Fair dummies test (classification score), p-value: 0.34865134865134867
experiment = 5
Coverage 0 = 0.9016141429669485
Coverage 1 = 0.9000774593338497
Length 0 = 1.4604150653343582
Length 1 = 1.4500387296669248
Prediction Error = 0.36304012345679015
p_val = 0.34865134865134867
AdversarialDebiasing_deep_model
Num experiments 05 | Avg. Pred Err = 0.3478 | Avg Length 0 = 1.4671 | Avg Length 1 = 1.4368 | Avg Coverage 0 = 0.8991 | Avg Coverage 1 = 0.9044 | Avg p_val = 0.3055 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.201224
Group 0 : Average length: 1.452946
Group 1 : Percentage in the range (expecting 90.00): 90.661479
Group 1 : Average length: 1.396887
Init Loss = 0.6877302
Final Loss = 0.35748118
Fair dummies test (classification score), p-value: 0.7502497502497503
experiment = 6
Coverage 0 = 0.9120122417750574
Coverage 1 = 0.9066147859922179
Length 0 = 1.4529456771231828
Length 1 = 1.3968871595330739
Prediction Error = 0.34452160493827155
p_val = 0.7502497502497503
AdversarialDebiasing_deep_model
Num experiments 06 | Avg. Pred Err = 0.3473 | Avg Length 0 = 1.4647 | Avg Length 1 = 1.4301 | Avg Coverage 0 = 0.9013 | Avg Coverage 1 = 0.9048 | Avg p_val = 0.3796 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.315275
Group 0 : Average length: 1.447705
Group 1 : Percentage in the range (expecting 90.00): 92.557403
Group 1 : Average length: 1.431512
Init Loss = 0.77589333
Final Loss = 0.46834004
Fair dummies test (classification score), p-value: 0.8641358641358642
experiment = 7
Coverage 0 = 0.8931527464258842
Coverage 1 = 0.9255740300870943
Length 0 = 1.4477050413844996
Length 1 = 1.4315122723673792
Prediction Error = 0.26003086419753085
p_val = 0.8641358641358642
AdversarialDebiasing_deep_model
Num experiments 07 | Avg. Pred Err = 0.3348 | Avg Length 0 = 1.4623 | Avg Length 1 = 1.4303 | Avg Coverage 0 = 0.9001 | Avg Coverage 1 = 0.9077 | Avg p_val = 0.4488 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.971941
Group 0 : Average length: 1.512860
Group 1 : Percentage in the range (expecting 90.00): 90.221543
Group 1 : Average length: 1.468296
Init Loss = 0.6910798
Final Loss = 0.4115075
Fair dummies test (classification score), p-value: 0.5354645354645354
experiment = 8
Coverage 0 = 0.9197194076383476
Coverage 1 = 0.9022154316271963
Length 0 = 1.5128604832424006
Length 1 = 1.46829640947288
Prediction Error = 0.37577160493827155
p_val = 0.5354645354645354
AdversarialDebiasing_deep_model
Num experiments 08 | Avg. Pred Err = 0.3399 | Avg Length 0 = 1.4686 | Avg Length 1 = 1.4351 | Avg Coverage 0 = 0.9026 | Avg Coverage 1 = 0.9070 | Avg p_val = 0.4597 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 92.313605
Group 0 : Average length: 1.510377
Group 1 : Percentage in the range (expecting 90.00): 88.381100
Group 1 : Average length: 1.456235
Init Loss = 0.73541915
Final Loss = 0.3542226
Fair dummies test (classification score), p-value: 0.2967032967032967
experiment = 9
Coverage 0 = 0.9231360491929285
Coverage 1 = 0.8838109992254066
Length 0 = 1.5103766333589546
Length 1 = 1.4562354763749032
Prediction Error = 0.33526234567901236
p_val = 0.2967032967032967
AdversarialDebiasing_deep_model
Num experiments 09 | Avg. Pred Err = 0.3394 | Avg Length 0 = 1.4733 | Avg Length 1 = 1.4374 | Avg Coverage 0 = 0.9049 | Avg Coverage 1 = 0.9045 | Avg p_val = 0.4416 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.158537
Group 0 : Average length: 2.019817
Group 1 : Percentage in the range (expecting 90.00): 89.296875
Group 1 : Average length: 1.980469
Init Loss = 0.67339456
Final Loss = 0.43521833
Fair dummies test (classification score), p-value: 0.6293706293706294
experiment = 10
Coverage 0 = 0.9115853658536586
Coverage 1 = 0.89296875
Length 0 = 2.019817073170732
Length 1 = 1.98046875
Prediction Error = 0.28202160493827155
p_val = 0.6293706293706294
AdversarialDebiasing_deep_model
Num experiments 10 | Avg. Pred Err = 0.3337 | Avg Length 0 = 1.5279 | Avg Length 1 = 1.4917 | Avg Coverage 0 = 0.9055 | Avg Coverage 1 = 0.9033 | Avg p_val = 0.4603 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.737654
Group 0 : Average length: 1.386574
Group 1 : Percentage in the range (expecting 90.00): 89.506173
Group 1 : Average length: 1.353395
Init Loss = 0.65443826
Final Loss = 0.4499888
Fair dummies test (classification score), p-value: 0.023976023976023976
experiment = 11
Coverage 0 = 0.8973765432098766
Coverage 1 = 0.8950617283950617
Length 0 = 1.3865740740740742
Length 1 = 1.353395061728395
Prediction Error = 0.23804012345679015
p_val = 0.023976023976023976
AdversarialDebiasing_deep_model
Num experiments 11 | Avg. Pred Err = 0.3250 | Avg Length 0 = 1.5151 | Avg Length 1 = 1.4791 | Avg Coverage 0 = 0.9048 | Avg Coverage 1 = 0.9026 | Avg p_val = 0.4207 | min p_val = 0.0190
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.377213
Group 0 : Average length: 1.387991
Group 1 : Percentage in the range (expecting 90.00): 89.559165
Group 1 : Average length: 1.350348
Init Loss = 0.63718396
Final Loss = 0.395313
Fair dummies test (classification score), p-value: 0.002997002997002997
experiment = 12
Coverage 0 = 0.9037721324095458
Coverage 1 = 0.8955916473317865
Length 0 = 1.3879907621247114
Length 1 = 1.3503480278422273
Prediction Error = 0.2407407407407407
p_val = 0.002997002997002997
AdversarialDebiasing_deep_model
Num experiments 12 | Avg. Pred Err = 0.3180 | Avg Length 0 = 1.5045 | Avg Length 1 = 1.4684 | Avg Coverage 0 = 0.9047 | Avg Coverage 1 = 0.9020 | Avg p_val = 0.3859 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.325426
Group 0 : Average length: 2.055597
Group 1 : Percentage in the range (expecting 90.00): 90.506838
Group 1 : Average length: 2.108608
Init Loss = 0.70354754
Final Loss = 0.36314288
Fair dummies test (classification score), p-value: 0.03196803196803197
experiment = 13
Coverage 0 = 0.8932542624166049
Coverage 1 = 0.9050683829444891
Length 0 = 2.055596738324685
Length 1 = 2.1086082059533386
Prediction Error = 0.31018518518518523
p_val = 0.03196803196803197
AdversarialDebiasing_deep_model
Num experiments 13 | Avg. Pred Err = 0.3174 | Avg Length 0 = 1.5469 | Avg Length 1 = 1.5177 | Avg Coverage 0 = 0.9038 | Avg Coverage 1 = 0.9022 | Avg p_val = 0.3586 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.189189
Group 0 : Average length: 1.807722
Group 1 : Percentage in the range (expecting 90.00): 90.670779
Group 1 : Average length: 1.819584
Init Loss = 0.6480589
Final Loss = 0.4462366
Fair dummies test (classification score), p-value: 0.34765234765234765
experiment = 14
Coverage 0 = 0.8918918918918919
Coverage 1 = 0.9067077872012336
Length 0 = 1.8077220077220078
Length 1 = 1.8195836545875097
Prediction Error = 0.24768518518518523
p_val = 0.34765234765234765
AdversarialDebiasing_deep_model
Num experiments 14 | Avg. Pred Err = 0.3124 | Avg Length 0 = 1.5655 | Avg Length 1 = 1.5392 | Avg Coverage 0 = 0.9030 | Avg Coverage 1 = 0.9025 | Avg p_val = 0.3579 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.277389
Group 0 : Average length: 1.491064
Group 1 : Percentage in the range (expecting 90.00): 89.655172
Group 1 : Average length: 1.439847
Init Loss = 0.7268216
Final Loss = 0.26000142
Fair dummies test (classification score), p-value: 0.6273726273726273
experiment = 15
Coverage 0 = 0.8927738927738927
Coverage 1 = 0.896551724137931
Length 0 = 1.491064491064491
Length 1 = 1.439846743295019
Prediction Error = 0.347608024691358
p_val = 0.6273726273726273
AdversarialDebiasing_deep_model
Num experiments 15 | Avg. Pred Err = 0.3147 | Avg Length 0 = 1.5605 | Avg Length 1 = 1.5326 | Avg Coverage 0 = 0.9023 | Avg Coverage 1 = 0.9021 | Avg p_val = 0.3758 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.146245
Group 0 : Average length: 1.460079
Group 1 : Percentage in the range (expecting 90.00): 89.223813
Group 1 : Average length: 1.355690
Init Loss = 0.7197452
Final Loss = 0.3847569
Fair dummies test (classification score), p-value: 0.0919080919080919
experiment = 16
Coverage 0 = 0.9114624505928853
Coverage 1 = 0.8922381311228335
Length 0 = 1.4600790513833992
Length 1 = 1.3556895252449133
Prediction Error = 0.23649691358024694
p_val = 0.0919080919080919
AdversarialDebiasing_deep_model
Num experiments 16 | Avg. Pred Err = 0.3098 | Avg Length 0 = 1.5543 | Avg Length 1 = 1.5215 | Avg Coverage 0 = 0.9029 | Avg Coverage 1 = 0.9015 | Avg p_val = 0.3581 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 92.313605
Group 0 : Average length: 1.510377
Group 1 : Percentage in the range (expecting 90.00): 90.007746
Group 1 : Average length: 1.431448
Init Loss = 0.69934857
Final Loss = 0.37836623
Fair dummies test (classification score), p-value: 0.27472527472527475
experiment = 17
Coverage 0 = 0.9231360491929285
Coverage 1 = 0.9000774593338497
Length 0 = 1.5103766333589546
Length 1 = 1.43144848954299
Prediction Error = 0.34490740740740744
p_val = 0.27472527472527475
AdversarialDebiasing_deep_model
Num experiments 17 | Avg. Pred Err = 0.3119 | Avg Length 0 = 1.5517 | Avg Length 1 = 1.5162 | Avg Coverage 0 = 0.9041 | Avg Coverage 1 = 0.9014 | Avg p_val = 0.3532 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.425287
Group 0 : Average length: 1.958621
Group 1 : Percentage in the range (expecting 90.00): 90.520591
Group 1 : Average length: 1.981352
Init Loss = 0.73308223
Final Loss = 0.41435704
Fair dummies test (classification score), p-value: 0.5464535464535465
experiment = 18
Coverage 0 = 0.8942528735632184
Coverage 1 = 0.9052059052059052
Length 0 = 1.9586206896551723
Length 1 = 1.9813519813519813
Prediction Error = 0.283179012345679
p_val = 0.5464535464535465
AdversarialDebiasing_deep_model
Num experiments 18 | Avg. Pred Err = 0.3103 | Avg Length 0 = 1.5743 | Avg Length 1 = 1.5421 | Avg Coverage 0 = 0.9035 | Avg Coverage 1 = 0.9016 | Avg p_val = 0.3639 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.593750
Group 0 : Average length: 1.400781
Group 1 : Percentage in the range (expecting 90.00): 87.957317
Group 1 : Average length: 1.355945
Init Loss = 0.6814406
Final Loss = 0.3824933
Fair dummies test (classification score), p-value: 0.006993006993006993
experiment = 19
Coverage 0 = 0.8859375
Coverage 1 = 0.8795731707317073
Length 0 = 1.40078125
Length 1 = 1.3559451219512195
Prediction Error = 0.3661265432098766
p_val = 0.006993006993006993
AdversarialDebiasing_deep_model
Num experiments 19 | Avg. Pred Err = 0.3133 | Avg Length 0 = 1.5652 | Avg Length 1 = 1.5323 | Avg Coverage 0 = 0.9026 | Avg Coverage 1 = 0.9005 | Avg p_val = 0.3451 | min p_val = 0.0030
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.384615
Group 0 : Average length: 1.411538
Group 1 : Percentage in the range (expecting 90.00): 89.473684
Group 1 : Average length: 1.360681
Init Loss = 0.79646707
Final Loss = 0.26695117
Fair dummies test (classification score), p-value: 0.25674325674325676
experiment = 20
Coverage 0 = 0.9138461538461539
Coverage 1 = 0.8947368421052632
Length 0 = 1.4115384615384616
Length 1 = 1.3606811145510835
Prediction Error = 0.2465277777777778
p_val = 0.25674325674325676
AdversarialDebiasing_deep_model
Num experiments 20 | Avg. Pred Err = 0.3099 | Avg Length 0 = 1.5575 | Avg Length 1 = 1.5237 | Avg Coverage 0 = 0.9031 | Avg Coverage 1 = 0.9002 | Avg p_val = 0.3407 | min p_val = 0.0030
======== Done =========
nursery
AdversarialDebiasing
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.285714
Group 0 : Average length: 1.222826
Group 1 : Percentage in the range (expecting 90.00): 90.720859
Group 1 : Average length: 1.152607
Init Loss = 0.6364346
Final Loss = 0.35073364
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 1
Coverage 0 = 0.8928571428571429
Coverage 1 = 0.9072085889570553
Length 0 = 1.2228260869565217
Length 1 = 1.1526073619631902
Prediction Error = 0.1747685185185185
p_val = 0.000999000999000999
AdversarialDebiasing_linear_model
Num experiments 01 | Avg. Pred Err = 0.1748 | Avg Length 0 = 1.2228 | Avg Length 1 = 1.1526 | Avg Coverage 0 = 0.8929 | Avg Coverage 1 = 0.9072 | Avg p_val = 0.0010 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.047393
Group 0 : Average length: 1.326224
Group 1 : Percentage in the range (expecting 90.00): 91.704374
Group 1 : Average length: 1.340121
Init Loss = 0.8199291
Final Loss = 0.2948598
Fair dummies test (classification score), p-value: 0.37362637362637363
experiment = 2
Coverage 0 = 0.9004739336492891
Coverage 1 = 0.9170437405731523
Length 0 = 1.3262243285939967
Length 1 = 1.3401206636500753
Prediction Error = 0.24189814814814814
p_val = 0.37362637362637363
AdversarialDebiasing_linear_model
Num experiments 02 | Avg. Pred Err = 0.2083 | Avg Length 0 = 1.2745 | Avg Length 1 = 1.2464 | Avg Coverage 0 = 0.8967 | Avg Coverage 1 = 0.9121 | Avg p_val = 0.1873 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.781874
Group 0 : Average length: 1.705069
Group 1 : Percentage in the range (expecting 90.00): 91.937984
Group 1 : Average length: 1.705426
Init Loss = 0.69997525
Final Loss = 0.45318264
Fair dummies test (classification score), p-value: 0.28771228771228774
experiment = 3
Coverage 0 = 0.9178187403993856
Coverage 1 = 0.9193798449612403
Length 0 = 1.705069124423963
Length 1 = 1.7054263565891472
Prediction Error = 0.34375
p_val = 0.28771228771228774
AdversarialDebiasing_linear_model
Num experiments 03 | Avg. Pred Err = 0.2535 | Avg Length 0 = 1.4180 | Avg Length 1 = 1.3994 | Avg Coverage 0 = 0.9037 | Avg Coverage 1 = 0.9145 | Avg p_val = 0.2208 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.435459
Group 0 : Average length: 1.578538
Group 1 : Percentage in the range (expecting 90.00): 90.658499
Group 1 : Average length: 1.737366
Init Loss = 0.7161152
Final Loss = 0.4727159
Fair dummies test (classification score), p-value: 0.14585414585414586
experiment = 4
Coverage 0 = 0.9043545878693624
Coverage 1 = 0.9065849923430321
Length 0 = 1.578538102643857
Length 1 = 1.737366003062787
Prediction Error = 0.3182870370370371
p_val = 0.14585414585414586
AdversarialDebiasing_linear_model
Num experiments 04 | Avg. Pred Err = 0.2697 | Avg Length 0 = 1.4582 | Avg Length 1 = 1.4839 | Avg Coverage 0 = 0.9039 | Avg Coverage 1 = 0.9126 | Avg p_val = 0.2020 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.622598
Group 0 : Average length: 1.458878
Group 1 : Percentage in the range (expecting 90.00): 91.402014
Group 1 : Average length: 1.513555
Init Loss = 0.6962146
Final Loss = 0.40564644
Fair dummies test (classification score), p-value: 0.8801198801198801
experiment = 5
Coverage 0 = 0.9062259800153728
Coverage 1 = 0.9140201394268009
Length 0 = 1.4588777863182167
Length 1 = 1.5135553834237025
Prediction Error = 0.23456790123456794
p_val = 0.8801198801198801
AdversarialDebiasing_linear_model
Num experiments 05 | Avg. Pred Err = 0.2627 | Avg Length 0 = 1.4583 | Avg Length 1 = 1.4898 | Avg Coverage 0 = 0.9043 | Avg Coverage 1 = 0.9128 | Avg p_val = 0.3377 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 87.758225
Group 0 : Average length: 1.432288
Group 1 : Percentage in the range (expecting 90.00): 91.284047
Group 1 : Average length: 1.495720
Init Loss = 0.7821138
Final Loss = 0.4103356
Fair dummies test (classification score), p-value: 0.44255744255744256
experiment = 6
Coverage 0 = 0.8775822494261668
Coverage 1 = 0.91284046692607
Length 0 = 1.4322876817138486
Length 1 = 1.4957198443579767
Prediction Error = 0.2662037037037037
p_val = 0.44255744255744256
AdversarialDebiasing_linear_model
Num experiments 06 | Avg. Pred Err = 0.2632 | Avg Length 0 = 1.4540 | Avg Length 1 = 1.4908 | Avg Coverage 0 = 0.8999 | Avg Coverage 1 = 0.9128 | Avg p_val = 0.3551 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 87.810384
Group 0 : Average length: 1.379985
Group 1 : Percentage in the range (expecting 90.00): 90.577989
Group 1 : Average length: 1.347585
Init Loss = 0.69426376
Final Loss = 0.40539476
Fair dummies test (classification score), p-value: 0.002997002997002997
experiment = 7
Coverage 0 = 0.8781038374717833
Coverage 1 = 0.9057798891528107
Length 0 = 1.3799849510910458
Length 1 = 1.3475851148060174
Prediction Error = 0.22376543209876543
p_val = 0.002997002997002997
AdversarialDebiasing_linear_model
Num experiments 07 | Avg. Pred Err = 0.2576 | Avg Length 0 = 1.4434 | Avg Length 1 = 1.4703 | Avg Coverage 0 = 0.8968 | Avg Coverage 1 = 0.9118 | Avg p_val = 0.3048 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.504287
Group 0 : Average length: 1.345284
Group 1 : Percentage in the range (expecting 90.00): 90.679908
Group 1 : Average length: 1.242170
Init Loss = 0.76314235
Final Loss = 0.3956655
Fair dummies test (classification score), p-value: 0.13286713286713286
experiment = 8
Coverage 0 = 0.9150428682774747
Coverage 1 = 0.9067990832696715
Length 0 = 1.3452844894777864
Length 1 = 1.2421695951107716
Prediction Error = 0.20177469135802473
p_val = 0.13286713286713286
AdversarialDebiasing_linear_model
Num experiments 08 | Avg. Pred Err = 0.2506 | Avg Length 0 = 1.4311 | Avg Length 1 = 1.4418 | Avg Coverage 0 = 0.8991 | Avg Coverage 1 = 0.9112 | Avg p_val = 0.2833 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.775557
Group 0 : Average length: 1.357417
Group 1 : Percentage in the range (expecting 90.00): 87.916344
Group 1 : Average length: 1.250968
Init Loss = 0.642707
Final Loss = 0.39849636
Fair dummies test (classification score), p-value: 0.04695304695304695
experiment = 9
Coverage 0 = 0.9177555726364335
Coverage 1 = 0.879163439194423
Length 0 = 1.3574173712528823
Length 1 = 1.2509682416731216
Prediction Error = 0.20293209876543206
p_val = 0.04695304695304695
AdversarialDebiasing_linear_model
Num experiments 09 | Avg. Pred Err = 0.2453 | Avg Length 0 = 1.4229 | Avg Length 1 = 1.4206 | Avg Coverage 0 = 0.9011 | Avg Coverage 1 = 0.9076 | Avg p_val = 0.2571 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.777439
Group 0 : Average length: 1.561738
Group 1 : Percentage in the range (expecting 90.00): 88.046875
Group 1 : Average length: 1.422656
Init Loss = 0.62604374
Final Loss = 0.45241702
Fair dummies test (classification score), p-value: 0.027972027972027972
experiment = 10
Coverage 0 = 0.9077743902439024
Coverage 1 = 0.88046875
Length 0 = 1.5617378048780488
Length 1 = 1.42265625
Prediction Error = 0.27854938271604934
p_val = 0.027972027972027972
AdversarialDebiasing_linear_model
Num experiments 10 | Avg. Pred Err = 0.2486 | Avg Length 0 = 1.4368 | Avg Length 1 = 1.4208 | Avg Coverage 0 = 0.9018 | Avg Coverage 1 = 0.9049 | Avg p_val = 0.2342 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.354938
Group 0 : Average length: 1.467593
Group 1 : Percentage in the range (expecting 90.00): 90.817901
Group 1 : Average length: 1.358796
Init Loss = 0.69469625
Final Loss = 0.38024867
Fair dummies test (classification score), p-value: 0.15384615384615385
experiment = 11
Coverage 0 = 0.9035493827160493
Coverage 1 = 0.908179012345679
Length 0 = 1.4675925925925926
Length 1 = 1.3587962962962963
Prediction Error = 0.22878086419753085
p_val = 0.15384615384615385
AdversarialDebiasing_linear_model
Num experiments 11 | Avg. Pred Err = 0.2468 | Avg Length 0 = 1.4396 | Avg Length 1 = 1.4152 | Avg Coverage 0 = 0.9020 | Avg Coverage 1 = 0.9052 | Avg p_val = 0.2269 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.992302
Group 0 : Average length: 1.319477
Group 1 : Percentage in the range (expecting 90.00): 91.569992
Group 1 : Average length: 1.327146
Init Loss = 0.6964921
Final Loss = 0.39625117
Fair dummies test (classification score), p-value: 0.008991008991008992
experiment = 12
Coverage 0 = 0.8999230177059276
Coverage 1 = 0.9156999226604795
Length 0 = 1.3194765204003078
Length 1 = 1.3271461716937354
Prediction Error = 0.22029320987654322
p_val = 0.008991008991008992
AdversarialDebiasing_linear_model
Num experiments 12 | Avg. Pred Err = 0.2446 | Avg Length 0 = 1.4296 | Avg Length 1 = 1.4078 | Avg Coverage 0 = 0.9018 | Avg Coverage 1 = 0.9061 | Avg p_val = 0.2087 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.363232
Group 0 : Average length: 1.481838
Group 1 : Percentage in the range (expecting 90.00): 90.506838
Group 1 : Average length: 1.481094
Init Loss = 0.6916106
Final Loss = 0.46559754
Fair dummies test (classification score), p-value: 0.5234765234765235
experiment = 13
Coverage 0 = 0.9036323202372127
Coverage 1 = 0.9050683829444891
Length 0 = 1.4818383988139363
Length 1 = 1.4810941271118263
Prediction Error = 0.2924382716049383
p_val = 0.5234765234765235
AdversarialDebiasing_linear_model
Num experiments 13 | Avg. Pred Err = 0.2483 | Avg Length 0 = 1.4336 | Avg Length 1 = 1.4135 | Avg Coverage 0 = 0.9019 | Avg Coverage 1 = 0.9060 | Avg p_val = 0.2329 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.266409
Group 0 : Average length: 1.521236
Group 1 : Percentage in the range (expecting 90.00): 87.895143
Group 1 : Average length: 1.581342
Init Loss = 0.61609733
Final Loss = 0.47404706
Fair dummies test (classification score), p-value: 0.12387612387612387
experiment = 14
Coverage 0 = 0.8926640926640926
Coverage 1 = 0.8789514263685428
Length 0 = 1.5212355212355213
Length 1 = 1.5813415574402467
Prediction Error = 0.3233024691358025
p_val = 0.12387612387612387
AdversarialDebiasing_linear_model
Num experiments 14 | Avg. Pred Err = 0.2537 | Avg Length 0 = 1.4399 | Avg Length 1 = 1.4255 | Avg Coverage 0 = 0.9013 | Avg Coverage 1 = 0.9041 | Avg p_val = 0.2251 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.121989
Group 0 : Average length: 1.233100
Group 1 : Percentage in the range (expecting 90.00): 89.348659
Group 1 : Average length: 1.190805
Init Loss = 0.661469
Final Loss = 0.37423363
Fair dummies test (classification score), p-value: 0.000999000999000999
experiment = 15
Coverage 0 = 0.8912198912198912
Coverage 1 = 0.8934865900383142
Length 0 = 1.2331002331002332
Length 1 = 1.1908045977011494
Prediction Error = 0.18479938271604934
p_val = 0.000999000999000999
AdversarialDebiasing_linear_model
Num experiments 15 | Avg. Pred Err = 0.2491 | Avg Length 0 = 1.4261 | Avg Length 1 = 1.4098 | Avg Coverage 0 = 0.9006 | Avg Coverage 1 = 0.9034 | Avg p_val = 0.2102 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.011858
Group 0 : Average length: 1.422925
Group 1 : Percentage in the range (expecting 90.00): 90.203466
Group 1 : Average length: 1.532781
Init Loss = 0.6540814
Final Loss = 0.44179535
Fair dummies test (classification score), p-value: 0.001998001998001998
experiment = 16
Coverage 0 = 0.8901185770750988
Coverage 1 = 0.9020346646571213
Length 0 = 1.4229249011857708
Length 1 = 1.5327807083647325
Prediction Error = 0.2866512345679012
p_val = 0.001998001998001998
AdversarialDebiasing_linear_model
Num experiments 16 | Avg. Pred Err = 0.2514 | Avg Length 0 = 1.4259 | Avg Length 1 = 1.4175 | Avg Coverage 0 = 0.8999 | Avg Coverage 1 = 0.9033 | Avg p_val = 0.1972 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 92.083013
Group 0 : Average length: 1.285165
Group 1 : Percentage in the range (expecting 90.00): 90.007746
Group 1 : Average length: 1.146398
Init Loss = 0.63973254
Final Loss = 0.33932745
Fair dummies test (classification score), p-value: 0.006993006993006993
experiment = 17
Coverage 0 = 0.9208301306687163
Coverage 1 = 0.9000774593338497
Length 0 = 1.2851652574942352
Length 1 = 1.1463981409759876
Prediction Error = 0.17785493827160492
p_val = 0.006993006993006993
AdversarialDebiasing_linear_model
Num experiments 17 | Avg. Pred Err = 0.2471 | Avg Length 0 = 1.4176 | Avg Length 1 = 1.4016 | Avg Coverage 0 = 0.9012 | Avg Coverage 1 = 0.9031 | Avg p_val = 0.1860 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.045977
Group 0 : Average length: 1.531801
Group 1 : Percentage in the range (expecting 90.00): 91.608392
Group 1 : Average length: 1.506605
Init Loss = 0.71809775
Final Loss = 0.39405036
Fair dummies test (classification score), p-value: 0.004995004995004995
experiment = 18
Coverage 0 = 0.8804597701149425
Coverage 1 = 0.916083916083916
Length 0 = 1.531800766283525
Length 1 = 1.5066045066045066
Prediction Error = 0.2758487654320988
p_val = 0.004995004995004995
AdversarialDebiasing_linear_model
Num experiments 18 | Avg. Pred Err = 0.2487 | Avg Length 0 = 1.4240 | Avg Length 1 = 1.4074 | Avg Coverage 0 = 0.9000 | Avg Coverage 1 = 0.9038 | Avg p_val = 0.1759 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.625000
Group 0 : Average length: 1.656250
Group 1 : Percentage in the range (expecting 90.00): 89.634146
Group 1 : Average length: 1.655488
Init Loss = 0.73773974
Final Loss = 0.40094495
Fair dummies test (classification score), p-value: 0.2937062937062937
experiment = 19
Coverage 0 = 0.90625
Coverage 1 = 0.8963414634146342
Length 0 = 1.65625
Length 1 = 1.6554878048780488
Prediction Error = 0.34104938271604934
p_val = 0.2937062937062937
AdversarialDebiasing_linear_model
Num experiments 19 | Avg. Pred Err = 0.2536 | Avg Length 0 = 1.4362 | Avg Length 1 = 1.4205 | Avg Coverage 0 = 0.9003 | Avg Coverage 1 = 0.9034 | Avg p_val = 0.1821 | min p_val = 0.0010
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.384615
Group 0 : Average length: 1.303077
Group 1 : Percentage in the range (expecting 90.00): 89.164087
Group 1 : Average length: 1.306502
Init Loss = 0.762671
Final Loss = 0.35515037
Fair dummies test (classification score), p-value: 0.47352647352647353
experiment = 20
Coverage 0 = 0.9038461538461539
Coverage 1 = 0.891640866873065
Length 0 = 1.303076923076923
Length 1 = 1.306501547987616
Prediction Error = 0.22839506172839508
p_val = 0.47352647352647353
AdversarialDebiasing_linear_model
Num experiments 20 | Avg. Pred Err = 0.2523 | Avg Length 0 = 1.4295 | Avg Length 1 = 1.4148 | Avg Coverage 0 = 0.9005 | Avg Coverage 1 = 0.9028 | Avg p_val = 0.1967 | min p_val = 0.0010
======== Done =========
nursery
FairDummies
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.198758
Group 0 : Average length: 1.581522
Group 1 : Percentage in the range (expecting 90.00): 89.570552
Group 1 : Average length: 1.691718
Init Loss = 0.730928
Final Loss = 0.53577775
Fair dummies test (classification score), p-value: 0.1838161838161838
experiment = 1
Coverage 0 = 0.8819875776397516
Coverage 1 = 0.8957055214723927
Length 0 = 1.5815217391304348
Length 1 = 1.6917177914110428
Prediction Error = 0.3067129629629629
p_val = 0.1838161838161838
FairDummies_linear_model
Num experiments 01 | Avg. Pred Err = 0.3067 | Avg Length 0 = 1.5815 | Avg Length 1 = 1.6917 | Avg Coverage 0 = 0.8820 | Avg Coverage 1 = 0.8957 | Avg p_val = 0.1838 | min p_val = 0.1838
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.178515
Group 0 : Average length: 1.728278
Group 1 : Percentage in the range (expecting 90.00): 90.497738
Group 1 : Average length: 1.788839
Init Loss = 0.70411706
Final Loss = 0.53632206
Fair dummies test (classification score), p-value: 0.1758241758241758
experiment = 2
Coverage 0 = 0.891785150078989
Coverage 1 = 0.9049773755656109
Length 0 = 1.7282780410742495
Length 1 = 1.7888386123680242
Prediction Error = 0.2885802469135802
p_val = 0.1758241758241758
FairDummies_linear_model
Num experiments 02 | Avg. Pred Err = 0.2976 | Avg Length 0 = 1.6549 | Avg Length 1 = 1.7403 | Avg Coverage 0 = 0.8869 | Avg Coverage 1 = 0.9003 | Avg p_val = 0.1798 | min p_val = 0.1758
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.858679
Group 0 : Average length: 1.602151
Group 1 : Percentage in the range (expecting 90.00): 89.069767
Group 1 : Average length: 1.458140
Init Loss = 0.68513054
Final Loss = 0.4004635
Fair dummies test (classification score), p-value: 0.13786213786213786
experiment = 3
Coverage 0 = 0.9185867895545314
Coverage 1 = 0.8906976744186047
Length 0 = 1.6021505376344085
Length 1 = 1.458139534883721
Prediction Error = 0.23263888888888884
p_val = 0.13786213786213786
FairDummies_linear_model
Num experiments 03 | Avg. Pred Err = 0.2760 | Avg Length 0 = 1.6373 | Avg Length 1 = 1.6462 | Avg Coverage 0 = 0.8975 | Avg Coverage 1 = 0.8971 | Avg p_val = 0.1658 | min p_val = 0.1379
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.269051
Group 0 : Average length: 2.448678
Group 1 : Percentage in the range (expecting 90.00): 90.275651
Group 1 : Average length: 2.276417
Init Loss = 0.71280986
Final Loss = 0.4850781
Fair dummies test (classification score), p-value: 0.38961038961038963
experiment = 4
Coverage 0 = 0.8926905132192846
Coverage 1 = 0.9027565084226646
Length 0 = 2.448678071539658
Length 1 = 2.276416539050536
Prediction Error = 0.3915895061728395
p_val = 0.38961038961038963
FairDummies_linear_model
Num experiments 04 | Avg. Pred Err = 0.3049 | Avg Length 0 = 1.8402 | Avg Length 1 = 1.8038 | Avg Coverage 0 = 0.8963 | Avg Coverage 1 = 0.8985 | Avg p_val = 0.2218 | min p_val = 0.1379
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.546503
Group 0 : Average length: 1.521138
Group 1 : Percentage in the range (expecting 90.00): 88.071263
Group 1 : Average length: 1.568552
Init Loss = 0.7709593
Final Loss = 0.5503633
Fair dummies test (classification score), p-value: 0.004995004995004995
experiment = 5
Coverage 0 = 0.8954650269023828
Coverage 1 = 0.8807126258714175
Length 0 = 1.5211375864719447
Length 1 = 1.56855151045701
Prediction Error = 0.29668209876543206
p_val = 0.004995004995004995
FairDummies_linear_model
Num experiments 05 | Avg. Pred Err = 0.3032 | Avg Length 0 = 1.7764 | Avg Length 1 = 1.7567 | Avg Coverage 0 = 0.8961 | Avg Coverage 1 = 0.8950 | Avg p_val = 0.1784 | min p_val = 0.0050
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.971691
Group 0 : Average length: 1.457536
Group 1 : Percentage in the range (expecting 90.00): 88.249027
Group 1 : Average length: 1.350973
Init Loss = 0.7351129
Final Loss = 0.45490384
Fair dummies test (classification score), p-value: 0.5224775224775224
experiment = 6
Coverage 0 = 0.909716908951798
Coverage 1 = 0.8824902723735408
Length 0 = 1.4575363427697017
Length 1 = 1.3509727626459145
Prediction Error = 0.24305555555555558
p_val = 0.5224775224775224
FairDummies_linear_model
Num experiments 06 | Avg. Pred Err = 0.2932 | Avg Length 0 = 1.7232 | Avg Length 1 = 1.6891 | Avg Coverage 0 = 0.8984 | Avg Coverage 1 = 0.8929 | Avg p_val = 0.2358 | min p_val = 0.0050
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.863807
Group 0 : Average length: 1.620015
Group 1 : Percentage in the range (expecting 90.00): 89.231987
Group 1 : Average length: 1.399050
Init Loss = 0.7513793
Final Loss = 0.44691393
Fair dummies test (classification score), p-value: 0.06493506493506493
experiment = 7
Coverage 0 = 0.8886380737396539
Coverage 1 = 0.8923198733174981
Length 0 = 1.6200150489089542
Length 1 = 1.3990498812351544
Prediction Error = 0.2542438271604939
p_val = 0.06493506493506493
FairDummies_linear_model
Num experiments 07 | Avg. Pred Err = 0.2876 | Avg Length 0 = 1.7085 | Avg Length 1 = 1.6477 | Avg Coverage 0 = 0.8970 | Avg Coverage 1 = 0.8928 | Avg p_val = 0.2114 | min p_val = 0.0050
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.660171
Group 0 : Average length: 1.785659
Group 1 : Percentage in the range (expecting 90.00): 90.450726
Group 1 : Average length: 1.683728
Init Loss = 0.76075494
Final Loss = 0.536822
Fair dummies test (classification score), p-value: 0.022977022977022976
experiment = 8
Coverage 0 = 0.916601714731099
Coverage 1 = 0.904507257448434
Length 0 = 1.7856586126266563
Length 1 = 1.6837280366692131
Prediction Error = 0.30594135802469136
p_val = 0.022977022977022976
FairDummies_linear_model
Num experiments 08 | Avg. Pred Err = 0.2899 | Avg Length 0 = 1.7181 | Avg Length 1 = 1.6522 | Avg Coverage 0 = 0.8994 | Avg Coverage 1 = 0.8943 | Avg p_val = 0.1878 | min p_val = 0.0050
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.083782
Group 0 : Average length: 2.891622
Group 1 : Percentage in the range (expecting 90.00): 87.993803
Group 1 : Average length: 2.484121
Init Loss = 0.7021646
Final Loss = 0.6770853
Fair dummies test (classification score), p-value: 0.04395604395604395
experiment = 9
Coverage 0 = 0.9108378170637971
Coverage 1 = 0.8799380325329202
Length 0 = 2.891621829362029
Length 1 = 2.4841208365608054
Prediction Error = 0.466820987654321
p_val = 0.04395604395604395
FairDummies_linear_model
Num experiments 09 | Avg. Pred Err = 0.3096 | Avg Length 0 = 1.8485 | Avg Length 1 = 1.7446 | Avg Coverage 0 = 0.9007 | Avg Coverage 1 = 0.8927 | Avg p_val = 0.1718 | min p_val = 0.0050
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.539634
Group 0 : Average length: 1.845274
Group 1 : Percentage in the range (expecting 90.00): 91.328125
Group 1 : Average length: 1.771094
Init Loss = 0.7118244
Final Loss = 0.449755
Fair dummies test (classification score), p-value: 0.942057942057942
experiment = 10
Coverage 0 = 0.9153963414634146
Coverage 1 = 0.91328125
Length 0 = 1.8452743902439024
Length 1 = 1.77109375
Prediction Error = 0.29359567901234573
p_val = 0.942057942057942
FairDummies_linear_model
Num experiments 10 | Avg. Pred Err = 0.3080 | Avg Length 0 = 1.8482 | Avg Length 1 = 1.7473 | Avg Coverage 0 = 0.9022 | Avg Coverage 1 = 0.8947 | Avg p_val = 0.2489 | min p_val = 0.0050
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.506173
Group 0 : Average length: 1.279321
Group 1 : Percentage in the range (expecting 90.00): 91.358025
Group 1 : Average length: 1.202932
Init Loss = 0.6911658
Final Loss = 0.3659383
Fair dummies test (classification score), p-value: 0.001998001998001998
experiment = 11
Coverage 0 = 0.8950617283950617
Coverage 1 = 0.9135802469135802
Length 0 = 1.279320987654321
Length 1 = 1.2029320987654322
Prediction Error = 0.18904320987654322
p_val = 0.001998001998001998
FairDummies_linear_model
Num experiments 11 | Avg. Pred Err = 0.2972 | Avg Length 0 = 1.7965 | Avg Length 1 = 1.6978 | Avg Coverage 0 = 0.9015 | Avg Coverage 1 = 0.8965 | Avg p_val = 0.2264 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.377983
Group 0 : Average length: 1.505774
Group 1 : Percentage in the range (expecting 90.00): 91.569992
Group 1 : Average length: 1.510441
Init Loss = 0.73627764
Final Loss = 0.42347205
Fair dummies test (classification score), p-value: 0.23076923076923078
experiment = 12
Coverage 0 = 0.9137798306389531
Coverage 1 = 0.9156999226604795
Length 0 = 1.5057736720554273
Length 1 = 1.5104408352668213
Prediction Error = 0.24151234567901236
p_val = 0.23076923076923078
FairDummies_linear_model
Num experiments 12 | Avg. Pred Err = 0.2925 | Avg Length 0 = 1.7722 | Avg Length 1 = 1.6822 | Avg Coverage 0 = 0.9025 | Avg Coverage 1 = 0.8981 | Avg p_val = 0.2268 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.585619
Group 0 : Average length: 1.977020
Group 1 : Percentage in the range (expecting 90.00): 89.460981
Group 1 : Average length: 1.977474
Init Loss = 0.7134309
Final Loss = 0.5901286
Fair dummies test (classification score), p-value: 0.9600399600399601
experiment = 13
Coverage 0 = 0.9058561897702001
Coverage 1 = 0.8946098149637972
Length 0 = 1.9770200148257968
Length 1 = 1.9774738535800482
Prediction Error = 0.376929012345679
p_val = 0.9600399600399601
FairDummies_linear_model
Num experiments 13 | Avg. Pred Err = 0.2990 | Avg Length 0 = 1.7880 | Avg Length 1 = 1.7049 | Avg Coverage 0 = 0.9028 | Avg Coverage 1 = 0.8978 | Avg p_val = 0.2832 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.343629
Group 0 : Average length: 1.797683
Group 1 : Percentage in the range (expecting 90.00): 91.210486
Group 1 : Average length: 1.686199
Init Loss = 0.6517488
Final Loss = 0.6123404
Fair dummies test (classification score), p-value: 0.008991008991008992
experiment = 14
Coverage 0 = 0.8934362934362934
Coverage 1 = 0.9121048573631457
Length 0 = 1.7976833976833977
Length 1 = 1.6861989205859675
Prediction Error = 0.3082561728395061
p_val = 0.008991008991008992
FairDummies_linear_model
Num experiments 14 | Avg. Pred Err = 0.2997 | Avg Length 0 = 1.7887 | Avg Length 1 = 1.7035 | Avg Coverage 0 = 0.9021 | Avg Coverage 1 = 0.8988 | Avg p_val = 0.2636 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 87.801088
Group 0 : Average length: 1.866356
Group 1 : Percentage in the range (expecting 90.00): 89.348659
Group 1 : Average length: 1.961686
Init Loss = 0.7648153
Final Loss = 0.49722552
Fair dummies test (classification score), p-value: 0.2957042957042957
experiment = 15
Coverage 0 = 0.878010878010878
Coverage 1 = 0.8934865900383142
Length 0 = 1.8663558663558664
Length 1 = 1.9616858237547892
Prediction Error = 0.32638888888888884
p_val = 0.2957042957042957
FairDummies_linear_model
Num experiments 15 | Avg. Pred Err = 0.3015 | Avg Length 0 = 1.7939 | Avg Length 1 = 1.7208 | Avg Coverage 0 = 0.9005 | Avg Coverage 1 = 0.8985 | Avg p_val = 0.2657 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.644269
Group 0 : Average length: 2.170751
Group 1 : Percentage in the range (expecting 90.00): 90.580256
Group 1 : Average length: 2.311228
Init Loss = 0.67662144
Final Loss = 0.5373341
Fair dummies test (classification score), p-value: 0.3026973026973027
experiment = 16
Coverage 0 = 0.8964426877470356
Coverage 1 = 0.905802562170309
Length 0 = 2.1707509881422924
Length 1 = 2.311228334589299
Prediction Error = 0.3912037037037037
p_val = 0.3026973026973027
FairDummies_linear_model
Num experiments 16 | Avg. Pred Err = 0.3071 | Avg Length 0 = 1.8174 | Avg Length 1 = 1.7577 | Avg Coverage 0 = 0.9003 | Avg Coverage 1 = 0.8989 | Avg p_val = 0.2680 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.775557
Group 0 : Average length: 1.400461
Group 1 : Percentage in the range (expecting 90.00): 90.472502
Group 1 : Average length: 1.316034
Init Loss = 0.6649199
Final Loss = 0.40981755
Fair dummies test (classification score), p-value: 0.996003996003996
experiment = 17
Coverage 0 = 0.9177555726364335
Coverage 1 = 0.9047250193648335
Length 0 = 1.4004611837048424
Length 1 = 1.3160340821068939
Prediction Error = 0.22337962962962965
p_val = 0.996003996003996
FairDummies_linear_model
Num experiments 17 | Avg. Pred Err = 0.3022 | Avg Length 0 = 1.7929 | Avg Length 1 = 1.7317 | Avg Coverage 0 = 0.9013 | Avg Coverage 1 = 0.8993 | Avg p_val = 0.3109 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.034483
Group 0 : Average length: 2.003831
Group 1 : Percentage in the range (expecting 90.00): 88.422688
Group 1 : Average length: 1.968143
Init Loss = 0.7105459
Final Loss = 0.6328061
Fair dummies test (classification score), p-value: 0.008991008991008992
experiment = 18
Coverage 0 = 0.9103448275862069
Coverage 1 = 0.8842268842268842
Length 0 = 2.003831417624521
Length 1 = 1.968142968142968
Prediction Error = 0.3495370370370371
p_val = 0.008991008991008992
FairDummies_linear_model
Num experiments 18 | Avg. Pred Err = 0.3048 | Avg Length 0 = 1.8046 | Avg Length 1 = 1.7448 | Avg Coverage 0 = 0.9018 | Avg Coverage 1 = 0.8984 | Avg p_val = 0.2941 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.828125
Group 0 : Average length: 2.009375
Group 1 : Percentage in the range (expecting 90.00): 89.939024
Group 1 : Average length: 2.088415
Init Loss = 0.6907428
Final Loss = 0.52980494
Fair dummies test (classification score), p-value: 0.4775224775224775
experiment = 19
Coverage 0 = 0.88828125
Coverage 1 = 0.899390243902439
Length 0 = 2.009375
Length 1 = 2.0884146341463414
Prediction Error = 0.36111111111111116
p_val = 0.4775224775224775
FairDummies_linear_model
Num experiments 19 | Avg. Pred Err = 0.3077 | Avg Length 0 = 1.8154 | Avg Length 1 = 1.7629 | Avg Coverage 0 = 0.9011 | Avg Coverage 1 = 0.8985 | Avg p_val = 0.3037 | min p_val = 0.0020
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.461538
Group 0 : Average length: 1.563077
Group 1 : Percentage in the range (expecting 90.00): 88.854489
Group 1 : Average length: 1.297988
Init Loss = 0.74539024
Final Loss = 0.41654563
Fair dummies test (classification score), p-value: 0.6423576423576424
experiment = 20
Coverage 0 = 0.9146153846153846
Coverage 1 = 0.8885448916408669
Length 0 = 1.563076923076923
Length 1 = 1.2979876160990713
Prediction Error = 0.22492283950617287
p_val = 0.6423576423576424
FairDummies_linear_model
Num experiments 20 | Avg. Pred Err = 0.3036 | Avg Length 0 = 1.8028 | Avg Length 1 = 1.7397 | Avg Coverage 0 = 0.9018 | Avg Coverage 1 = 0.8980 | Avg p_val = 0.3207 | min p_val = 0.0020
======== Done =========
nursery
FairDummies
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 87.965839
Group 0 : Average length: 1.315217
Group 1 : Percentage in the range (expecting 90.00): 88.650307
Group 1 : Average length: 1.305215
Init Loss = 0.6748977
Final Loss = 0.44331586
Fair dummies test (classification score), p-value: 0.2707292707292707
experiment = 1
Coverage 0 = 0.8796583850931677
Coverage 1 = 0.8865030674846626
Length 0 = 1.315217391304348
Length 1 = 1.3052147239263803
Prediction Error = 0.23379629629629628
p_val = 0.2707292707292707
FairDummies_deep_model
Num experiments 01 | Avg. Pred Err = 0.2338 | Avg Length 0 = 1.3152 | Avg Length 1 = 1.3052 | Avg Coverage 0 = 0.8797 | Avg Coverage 1 = 0.8865 | Avg p_val = 0.2707 | min p_val = 0.2707
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.230648
Group 0 : Average length: 1.436809
Group 1 : Percentage in the range (expecting 90.00): 91.025641
Group 1 : Average length: 1.436652
Init Loss = 0.7189855
Final Loss = 0.45264712
Fair dummies test (classification score), p-value: 0.5844155844155844
experiment = 2
Coverage 0 = 0.882306477093207
Coverage 1 = 0.9102564102564102
Length 0 = 1.4368088467614535
Length 1 = 1.4366515837104072
Prediction Error = 0.2901234567901234
p_val = 0.5844155844155844
FairDummies_deep_model
Num experiments 02 | Avg. Pred Err = 0.2620 | Avg Length 0 = 1.3760 | Avg Length 1 = 1.3709 | Avg Coverage 0 = 0.8810 | Avg Coverage 1 = 0.8984 | Avg p_val = 0.4276 | min p_val = 0.2707
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.013825
Group 0 : Average length: 1.423195
Group 1 : Percentage in the range (expecting 90.00): 91.162791
Group 1 : Average length: 1.412403
Init Loss = 0.73378396
Final Loss = 0.4515047
Fair dummies test (classification score), p-value: 0.36563436563436563
experiment = 3
Coverage 0 = 0.9101382488479263
Coverage 1 = 0.9116279069767442
Length 0 = 1.423195084485407
Length 1 = 1.4124031007751938
Prediction Error = 0.2542438271604939
p_val = 0.36563436563436563
FairDummies_deep_model
Num experiments 03 | Avg. Pred Err = 0.2594 | Avg Length 0 = 1.3917 | Avg Length 1 = 1.3848 | Avg Coverage 0 = 0.8907 | Avg Coverage 1 = 0.9028 | Avg p_val = 0.4069 | min p_val = 0.2707
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.046656
Group 0 : Average length: 1.373250
Group 1 : Percentage in the range (expecting 90.00): 90.964778
Group 1 : Average length: 1.316998
Init Loss = 0.6613652
Final Loss = 0.45627537
Fair dummies test (classification score), p-value: 0.05994005994005994
experiment = 4
Coverage 0 = 0.9004665629860031
Coverage 1 = 0.9096477794793262
Length 0 = 1.3732503888024883
Length 1 = 1.3169984686064318
Prediction Error = 0.20524691358024694
p_val = 0.05994005994005994
FairDummies_deep_model
Num experiments 04 | Avg. Pred Err = 0.2459 | Avg Length 0 = 1.3871 | Avg Length 1 = 1.3678 | Avg Coverage 0 = 0.8931 | Avg Coverage 1 = 0.9045 | Avg p_val = 0.3202 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.468870
Group 0 : Average length: 1.411991
Group 1 : Percentage in the range (expecting 90.00): 91.324555
Group 1 : Average length: 1.359411
Init Loss = 0.6388149
Final Loss = 0.4372998
Fair dummies test (classification score), p-value: 0.24175824175824176
experiment = 5
Coverage 0 = 0.9046887009992314
Coverage 1 = 0.9132455460883037
Length 0 = 1.4119907763259032
Length 1 = 1.359411309062742
Prediction Error = 0.23109567901234573
p_val = 0.24175824175824176
FairDummies_deep_model
Num experiments 05 | Avg. Pred Err = 0.2429 | Avg Length 0 = 1.3921 | Avg Length 1 = 1.3661 | Avg Coverage 0 = 0.8955 | Avg Coverage 1 = 0.9063 | Avg p_val = 0.3045 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.895180
Group 0 : Average length: 1.482785
Group 1 : Percentage in the range (expecting 90.00): 90.505837
Group 1 : Average length: 1.456031
Init Loss = 0.6680998
Final Loss = 0.44809347
Fair dummies test (classification score), p-value: 0.6983016983016983
experiment = 6
Coverage 0 = 0.9089517980107116
Coverage 1 = 0.9050583657587549
Length 0 = 1.4827850038255548
Length 1 = 1.4560311284046692
Prediction Error = 0.2939814814814815
p_val = 0.6983016983016983
FairDummies_deep_model
Num experiments 06 | Avg. Pred Err = 0.2514 | Avg Length 0 = 1.4072 | Avg Length 1 = 1.3811 | Avg Coverage 0 = 0.8977 | Avg Coverage 1 = 0.9061 | Avg p_val = 0.3701 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.315275
Group 0 : Average length: 1.420617
Group 1 : Percentage in the range (expecting 90.00): 89.944576
Group 1 : Average length: 1.361837
Init Loss = 0.69596344
Final Loss = 0.4454576
Fair dummies test (classification score), p-value: 0.07292707292707293
experiment = 7
Coverage 0 = 0.8931527464258842
Coverage 1 = 0.89944576405384
Length 0 = 1.420617005267118
Length 1 = 1.3618368962787015
Prediction Error = 0.2534722222222222
p_val = 0.07292707292707293
FairDummies_deep_model
Num experiments 07 | Avg. Pred Err = 0.2517 | Avg Length 0 = 1.4091 | Avg Length 1 = 1.3784 | Avg Coverage 0 = 0.8971 | Avg Coverage 1 = 0.9051 | Avg p_val = 0.3277 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 92.829306
Group 0 : Average length: 1.480125
Group 1 : Percentage in the range (expecting 90.00): 90.603514
Group 1 : Average length: 1.439267
Init Loss = 0.6852889
Final Loss = 0.46516734
Fair dummies test (classification score), p-value: 0.6883116883116883
experiment = 8
Coverage 0 = 0.9282930631332814
Coverage 1 = 0.906035141329259
Length 0 = 1.48012470771629
Length 1 = 1.439266615737204
Prediction Error = 0.28125
p_val = 0.6883116883116883
FairDummies_deep_model
Num experiments 08 | Avg. Pred Err = 0.2554 | Avg Length 0 = 1.4180 | Avg Length 1 = 1.3860 | Avg Coverage 0 = 0.9010 | Avg Coverage 1 = 0.9052 | Avg p_val = 0.3728 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.775557
Group 0 : Average length: 1.404304
Group 1 : Percentage in the range (expecting 90.00): 89.388071
Group 1 : Average length: 1.351665
Init Loss = 0.6717953
Final Loss = 0.4574076
Fair dummies test (classification score), p-value: 0.0939060939060939
experiment = 9
Coverage 0 = 0.9177555726364335
Coverage 1 = 0.8938807126258714
Length 0 = 1.404304381245196
Length 1 = 1.3516653756777692
Prediction Error = 0.2573302469135802
p_val = 0.0939060939060939
FairDummies_deep_model
Num experiments 09 | Avg. Pred Err = 0.2556 | Avg Length 0 = 1.4165 | Avg Length 1 = 1.3822 | Avg Coverage 0 = 0.9028 | Avg Coverage 1 = 0.9040 | Avg p_val = 0.3418 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 90.625000
Group 0 : Average length: 1.477896
Group 1 : Percentage in the range (expecting 90.00): 90.468750
Group 1 : Average length: 1.425000
Init Loss = 0.78827167
Final Loss = 0.44788337
Fair dummies test (classification score), p-value: 0.8761238761238761
experiment = 10
Coverage 0 = 0.90625
Coverage 1 = 0.9046875
Length 0 = 1.4778963414634145
Length 1 = 1.425
Prediction Error = 0.2854938271604939
p_val = 0.8761238761238761
FairDummies_deep_model
Num experiments 10 | Avg. Pred Err = 0.2586 | Avg Length 0 = 1.4226 | Avg Length 1 = 1.3864 | Avg Coverage 0 = 0.9032 | Avg Coverage 1 = 0.9040 | Avg p_val = 0.3952 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.969136
Group 0 : Average length: 1.410494
Group 1 : Percentage in the range (expecting 90.00): 90.586420
Group 1 : Average length: 1.394290
Init Loss = 0.6401357
Final Loss = 0.45296544
Fair dummies test (classification score), p-value: 0.9660339660339661
experiment = 11
Coverage 0 = 0.8996913580246914
Coverage 1 = 0.9058641975308642
Length 0 = 1.4104938271604939
Length 1 = 1.3942901234567902
Prediction Error = 0.24691358024691357
p_val = 0.9660339660339661
FairDummies_deep_model
Num experiments 11 | Avg. Pred Err = 0.2575 | Avg Length 0 = 1.4215 | Avg Length 1 = 1.3872 | Avg Coverage 0 = 0.9029 | Avg Coverage 1 = 0.9042 | Avg p_val = 0.4471 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.070054
Group 0 : Average length: 1.371824
Group 1 : Percentage in the range (expecting 90.00): 88.708430
Group 1 : Average length: 1.314772
Init Loss = 0.7202886
Final Loss = 0.45064318
Fair dummies test (classification score), p-value: 0.1978021978021978
experiment = 12
Coverage 0 = 0.9107005388760585
Coverage 1 = 0.8870843000773395
Length 0 = 1.371824480369515
Length 1 = 1.3147718484145399
Prediction Error = 0.22723765432098764
p_val = 0.1978021978021978
FairDummies_deep_model
Num experiments 12 | Avg. Pred Err = 0.2550 | Avg Length 0 = 1.4174 | Avg Length 1 = 1.3811 | Avg Coverage 0 = 0.9035 | Avg Coverage 1 = 0.9028 | Avg p_val = 0.4263 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.287620
Group 0 : Average length: 1.379540
Group 1 : Percentage in the range (expecting 90.00): 88.817377
Group 1 : Average length: 1.359614
Init Loss = 0.7725926
Final Loss = 0.4598947
Fair dummies test (classification score), p-value: 0.7732267732267732
experiment = 13
Coverage 0 = 0.882876204595997
Coverage 1 = 0.8881737731295254
Length 0 = 1.379540400296516
Length 1 = 1.3596138374899436
Prediction Error = 0.22685185185185186
p_val = 0.7732267732267732
FairDummies_deep_model
Num experiments 13 | Avg. Pred Err = 0.2528 | Avg Length 0 = 1.4145 | Avg Length 1 = 1.3795 | Avg Coverage 0 = 0.9019 | Avg Coverage 1 = 0.9017 | Avg p_val = 0.4530 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.725869
Group 0 : Average length: 1.377606
Group 1 : Percentage in the range (expecting 90.00): 90.131072
Group 1 : Average length: 1.378566
Init Loss = 0.7206291
Final Loss = 0.46178558
Fair dummies test (classification score), p-value: 0.07892107892107893
experiment = 14
Coverage 0 = 0.8872586872586873
Coverage 1 = 0.9013107170393215
Length 0 = 1.3776061776061777
Length 1 = 1.3785659213569776
Prediction Error = 0.25848765432098764
p_val = 0.07892107892107893
FairDummies_deep_model
Num experiments 14 | Avg. Pred Err = 0.2533 | Avg Length 0 = 1.4118 | Avg Length 1 = 1.3794 | Avg Coverage 0 = 0.9009 | Avg Coverage 1 = 0.9016 | Avg p_val = 0.4263 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.821290
Group 0 : Average length: 1.488733
Group 1 : Percentage in the range (expecting 90.00): 89.272031
Group 1 : Average length: 1.448276
Init Loss = 0.749748
Final Loss = 0.43853006
Fair dummies test (classification score), p-value: 0.8271728271728271
experiment = 15
Coverage 0 = 0.8982128982128982
Coverage 1 = 0.89272030651341
Length 0 = 1.4887334887334887
Length 1 = 1.4482758620689655
Prediction Error = 0.3638117283950617
p_val = 0.8271728271728271
FairDummies_deep_model
Num experiments 15 | Avg. Pred Err = 0.2606 | Avg Length 0 = 1.4170 | Avg Length 1 = 1.3840 | Avg Coverage 0 = 0.9007 | Avg Coverage 1 = 0.9010 | Avg p_val = 0.4530 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.328063
Group 0 : Average length: 1.408696
Group 1 : Percentage in the range (expecting 90.00): 90.429540
Group 1 : Average length: 1.394122
Init Loss = 0.7671569
Final Loss = 0.4563481
Fair dummies test (classification score), p-value: 0.2787212787212787
experiment = 16
Coverage 0 = 0.8932806324110671
Coverage 1 = 0.9042954031650339
Length 0 = 1.4086956521739131
Length 1 = 1.3941220798794274
Prediction Error = 0.2534722222222222
p_val = 0.2787212787212787
FairDummies_deep_model
Num experiments 16 | Avg. Pred Err = 0.2602 | Avg Length 0 = 1.4164 | Avg Length 1 = 1.3846 | Avg Coverage 0 = 0.9002 | Avg Coverage 1 = 0.9012 | Avg p_val = 0.4421 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.160646
Group 0 : Average length: 1.335127
Group 1 : Percentage in the range (expecting 90.00): 89.852827
Group 1 : Average length: 1.320682
Init Loss = 0.7312061
Final Loss = 0.42757556
Fair dummies test (classification score), p-value: 0.12387612387612387
experiment = 17
Coverage 0 = 0.9116064565718678
Coverage 1 = 0.8985282726568552
Length 0 = 1.3351268255188318
Length 1 = 1.3206816421378775
Prediction Error = 0.2276234567901234
p_val = 0.12387612387612387
FairDummies_deep_model
Num experiments 17 | Avg. Pred Err = 0.2583 | Avg Length 0 = 1.4117 | Avg Length 1 = 1.3809 | Avg Coverage 0 = 0.9009 | Avg Coverage 1 = 0.9011 | Avg p_val = 0.4234 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 89.808429
Group 0 : Average length: 1.352490
Group 1 : Percentage in the range (expecting 90.00): 89.743590
Group 1 : Average length: 1.369075
Init Loss = 0.693083
Final Loss = 0.4577816
Fair dummies test (classification score), p-value: 0.6853146853146853
experiment = 18
Coverage 0 = 0.8980842911877395
Coverage 1 = 0.8974358974358975
Length 0 = 1.3524904214559388
Length 1 = 1.369075369075369
Prediction Error = 0.2442129629629629
p_val = 0.6853146853146853
FairDummies_deep_model
Num experiments 18 | Avg. Pred Err = 0.2575 | Avg Length 0 = 1.4084 | Avg Length 1 = 1.3802 | Avg Coverage 0 = 0.9007 | Avg Coverage 1 = 0.9009 | Avg p_val = 0.4380 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 88.437500
Group 0 : Average length: 1.334375
Group 1 : Percentage in the range (expecting 90.00): 90.701220
Group 1 : Average length: 1.365091
Init Loss = 0.6867742
Final Loss = 0.43266216
Fair dummies test (classification score), p-value: 0.4835164835164835
experiment = 19
Coverage 0 = 0.884375
Coverage 1 = 0.9070121951219512
Length 0 = 1.334375
Length 1 = 1.365091463414634
Prediction Error = 0.23572530864197527
p_val = 0.4835164835164835
FairDummies_deep_model
Num experiments 19 | Avg. Pred Err = 0.2563 | Avg Length 0 = 1.4045 | Avg Length 1 = 1.3794 | Avg Coverage 0 = 0.8999 | Avg Coverage 1 = 0.9012 | Avg p_val = 0.4403 | min p_val = 0.0599
======== Done =========
n train = 7774 p = 13
n calibration = 2592
n test = 2592
Group 0 : Percentage in the range (expecting 90.00): 91.384615
Group 0 : Average length: 1.411538
Group 1 : Percentage in the range (expecting 90.00): 89.241486
Group 1 : Average length: 1.330495
Init Loss = 0.7240916
Final Loss = 0.44070697
Fair dummies test (classification score), p-value: 0.07992007992007992
experiment = 20
Coverage 0 = 0.9138461538461539
Coverage 1 = 0.8924148606811145
Length 0 = 1.4115384615384616
Length 1 = 1.3304953560371517
Prediction Error = 0.21990740740740744
p_val = 0.07992007992007992
FairDummies_deep_model
Num experiments 20 | Avg. Pred Err = 0.2545 | Avg Length 0 = 1.4048 | Avg Length 1 = 1.3770 | Avg Coverage 0 = 0.9006 | Avg Coverage 1 = 0.9008 | Avg p_val = 0.4223 | min p_val = 0.0599
======== Done =========
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/utils/multiclass.py:13: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.
  from scipy.sparse.base import spmatrix
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  method='lar', copy_X=True, eps=np.finfo(np.float).eps,
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  method='lar', copy_X=True, eps=np.finfo(np.float).eps,
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, positive=False):
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, positive=False):
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe2` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.
  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe1` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.
  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  EPS = np.finfo(np.float).eps
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from ._gradient_boosting import predict_stages
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from ._gradient_boosting import predict_stages
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/mt1/21CS60D06/anaconda3/envs/fair/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
