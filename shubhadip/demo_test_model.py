# -*- coding: utf-8 -*-
"""demo_test_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11GqeGKO-PBP4ftg7XyB1BfdXZV--1sFK
"""

import torch
import random
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
import torchvision
from torch.utils.data import Dataset
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler
import os
################# Creating training dataset class #################

class AdultData(torch.utils.data.Dataset):

  def __init__(self, X, y, z, scale_data=True):
    if not torch.is_tensor(X) and not torch.is_tensor(y):
      self.X = torch.from_numpy(X)
      self.y = torch.from_numpy(y)
      self.z = torch.from_numpy(z)

  def __len__(self):
      return len(self.X)

  def __getitem__(self, i):
      return self.X[i], self.y[i], self.z[i], i



class Dataset(object):

    def __init__(self):

        data = pd.read_csv('propublica_data_for_fairml.csv', na_values='?')
        scaler = StandardScaler()
        data[['Number_of_Priors']] = scaler.fit_transform(data[['Number_of_Priors']])
        X = data.drop(['Two_yr_Recidivism'],axis=1).values
        y = data['Two_yr_Recidivism'].values
        z = data['Female'].values
        
        X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(X, y, z, test_size = 0.2, random_state = 42)
        

        self.trainset = AdultData(X_train, y_train, z_train)
        self.testset = AdultData(X_test, y_test, z_test)
        #print(len(self.trainset))
        #print(len(self.testset))

        self.z_test = z_test
        self.y_test = y_test
        self.y = y_train

    def load_data(self):

        trainloader = torch.utils.data.DataLoader(self.trainset, batch_size = 1, shuffle=False, num_workers=2)
        testloader = torch.utils.data.DataLoader(self.testset, batch_size=10, shuffle=False, num_workers=2)

        return trainloader, testloader, self.trainset, self.z_test, self.y_test, self.y

import torch.nn as nn
import torch.nn.functional as F

class Network(nn.Module):

  def __init__(self):
    super().__init__()
    self.layer1 = nn.Linear(11,64) 
    self.activ1 = nn.ReLU()
    self.layer2 = nn.Linear(64, 32)
    self.activ2 = nn.ReLU()
    self.layer3 = nn.Linear(32,2)


  def forward(self, x):
    out = self.activ1(self.layer1(x))
    out = self.activ2(self.layer2(out))
    out = self.layer3(out)

    return out

import torch.optim as optim
torch.manual_seed(123)
net = Network()
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.0005, weight_decay=0.01)

ds = Dataset()
trainloader, testloader, trainset, z_test, y_test, Y = ds.load_data()

#FUNCTION FOR TESTING THE MODEL
#y = labels, prediction = predicted value, s1 = sensitive att.(z)
def test_model(y, prediction, s1):
    y = y.squeeze()
    s1 = s1.squeeze()
    

    z_0_mask = (s1 == 0.0)
    z_1_mask = (s1 == 1.0)
    z_0 = int(torch.sum(z_0_mask))
    z_1 = int(torch.sum(z_1_mask))
    
    y_0_mask = (y == 0.0)
    y_1_mask = (y == 1.0)
    y_0 = int(torch.sum(y_0_mask))
    y_1 = int(torch.sum(y_1_mask))
    
    Pr_y_hat_1 = float(torch.sum((prediction == 1))) / (z_0 + z_1)
    
    Pr_y_hat_1_z_0 = float(torch.sum((prediction == 1)[z_0_mask])) / z_0
    Pr_y_hat_1_z_1 = float(torch.sum((prediction == 1)[z_1_mask])) / z_1
        
    
    y_1_z_0_mask = (y == 1.0) & (s1 == 0.0)
    y_1_z_1_mask = (y == 1.0) & (s1 == 1.0)
    y_1_z_0 = int(torch.sum(y_1_z_0_mask))
    y_1_z_1 = int(torch.sum(y_1_z_1_mask))
    
    Pr_y_hat_1_y_0 = float(torch.sum((prediction == 1)[y_0_mask])) / y_0
    Pr_y_hat_1_y_1 = float(torch.sum((prediction == 1)[y_1_mask])) / y_1
    
    Pr_y_hat_1_y_1_z_0 = float(torch.sum((prediction == 1)[y_1_z_0_mask])) / y_1_z_0
    Pr_y_hat_1_y_1_z_1 = float(torch.sum((prediction == 1)[y_1_z_1_mask])) / y_1_z_1
    
    y_0_z_0_mask = (y == 0.0) & (s1 == 0.0)
    y_0_z_1_mask = (y == 0.0) & (s1 == 1.0)
    y_0_z_0 = int(torch.sum(y_0_z_0_mask))
    y_0_z_1 = int(torch.sum(y_0_z_1_mask))

    Pr_y_hat_1_y_0_z_0 = float(torch.sum((prediction == 1)[y_0_z_0_mask])) / y_0_z_0
    Pr_y_hat_1_y_0_z_1 = float(torch.sum((prediction == 1)[y_0_z_1_mask])) / y_0_z_1
    
    recall = Pr_y_hat_1_y_1
    precision = float(torch.sum((prediction == 1)[y_1_mask])) / (int(torch.sum(prediction == 1)) + 0.00001)
    
    y_hat_neq_y = float(torch.sum((prediction == y.int())))

    #test_acc = torch.sum(prediction == y.int()).float() / len(y)
    test_f1 = 2 * recall * precision / (recall+precision+0.00001)
    
    min_dp = min(Pr_y_hat_1_z_0, Pr_y_hat_1_z_1) + 0.00001
    max_dp = max(Pr_y_hat_1_z_0, Pr_y_hat_1_z_1) + 0.00001
    min_eo_0 = min(Pr_y_hat_1_y_0_z_0, Pr_y_hat_1_y_0_z_1) + 0.00001
    max_eo_0 = max(Pr_y_hat_1_y_0_z_0, Pr_y_hat_1_y_0_z_1) + 0.00001
    min_eo_1 = min(Pr_y_hat_1_y_1_z_0, Pr_y_hat_1_y_1_z_1) + 0.00001
    max_eo_1 = max(Pr_y_hat_1_y_1_z_0, Pr_y_hat_1_y_1_z_1) + 0.00001
    
    DP = max(abs(Pr_y_hat_1_z_0 - Pr_y_hat_1), abs(Pr_y_hat_1_z_1 - Pr_y_hat_1))
    
    EO_Y_0 = max(abs(Pr_y_hat_1_y_0_z_0 - Pr_y_hat_1_y_0), abs(Pr_y_hat_1_y_0_z_1 - Pr_y_hat_1_y_0))
    EO_Y_1 = max(abs(Pr_y_hat_1_y_1_z_0 - Pr_y_hat_1_y_1), abs(Pr_y_hat_1_y_1_z_1 - Pr_y_hat_1_y_1))

    
    return {'DP_diff': DP, 'EO_Y0_diff': EO_Y_0, 'EO_Y1_diff': EO_Y_1, 'EqOdds_diff': max(EO_Y_0, EO_Y_1)}

net = Network()
net.load_state_dict(torch.load('./checkpoint_sub/compas.pth'))

pred = []
correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in testloader:
        inputs, labels, s, _ = data
        outputs = net(inputs.float())
        
        _, idx = torch.max(outputs,dim=-1)
        pred.append(idx.tolist())
        #print(idx, labels.squeeze())
        correct += (idx == labels.squeeze()).sum()
        total += labels.size(0)
        
print(f'Accuracy of the network : {100 * correct / total} %')

from itertools import chain
pred = list(chain.from_iterable(pred))

res = test_model(torch.from_numpy(y_test), torch.Tensor(pred), torch.from_numpy(z_test))

print("EO disparity: {}, DP disparity: {}".format(res['EqOdds_diff'], res['DP_diff']))